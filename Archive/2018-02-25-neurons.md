---
layout: post
title: "Artificial Neurons"
date: 2018-02-25 15:57:47
image: '/assets/img/'
description: 'Introduction to Artificial Neurons'
tags:
- sigmoid
- bias
- neural nets
- training
- layers
categories:
- Intel AI Machine Leaning
twitter_text: 
---

# Background
Neural networks are old, the first models appeared in the early 1940's, and the idea has been refined by many generations of great scientists. They took inspiration from biology to create a mathematical model, that takes in signals from previous neurons to generate signals that match the input. By layering many neurons, one can create a sophisticated model that can work as a useful function approximator.

## Neural Net Structure
A neural network `maps inputs to outputs`. You can think of it as a complex computational engine that can be trained to learn the features of a given training set.

![Output](/assets/img/NeuralNets/9.png){:class="img-responsive"}

## A basic neuron

`z` is the `"net input"` from the data or the layer preceding.
`b` is the `"bias term`, used to fine-tune the networks

![Output](/assets/img/NeuralNets/10.png){:class="img-responsive"}
### Vector Notation
We can go further and simplify the `z` function for large vectors as:
![Output](/assets/img/NeuralNets/11.png){:class="img-responsive"}

Lets now define the `output to the next layer`, `"a"`, which uses an `activation function`, `"f"` over the `input data`,`"z"`.
![Output](/assets/img/NeuralNets/12.png){:class="img-responsive"}

### In Relation to Logistic Regression
When we choose the `activation function` as the sigmoid function
![Output](/assets/img/NeuralNets/13.png){:class="img-responsive"}
Then the neuron merely becomes a "unit" of logistic regression!
Where:

inputs -> variables
weights -> coefficients
bias term -> constant term(intersect)

#### A Nice property of sigmoid function
When differentiated the function it can be simplified easily, by utilising the quotient rule
![Output](/assets/img/NeuralNets/14.png){:class="img-responsive"}


## An example of a Neural Computation
![Output](/assets/img/NeuralNets/15.png){:class="img-responsive"}

# Why Neural Nets
**A good question is why not use a single neuron, why do we need large networks?**
Well, a single neuron (like a linear regression) only permits a linear decision boundary. Most real-world problems are much more complicated, so we can layer them up to form a better function approximator.



