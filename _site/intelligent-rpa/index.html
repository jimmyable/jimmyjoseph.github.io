<!DOCTYPE html>
<html lang="pt-br">
    <head>
    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1">

    <title>Using ML to filter tasks for RPA</title>
    <meta name="description" content="Not all process are primed for RPA, and this is not black and white. Some process may have counterparts which are automatable. It is a matter of being able t...">

    <!-- Google Authorship Markup -->
    <link rel="author" href="https://plus.google.com/jimmyjoseph1295?rel=author">

    <!-- Social: Twitter -->
    <meta name="twitter:card" content="summary_large_image">
    <meta name="twitter:site" content="@jimmyable_">
    <meta name="twitter:title" content="Using ML to filter tasks for RPA">
    <meta name="twitter:description" content="Not all process are primed for RPA, and this is not black and white. Some process may have counterparts which are automatable. It is a matter of being able t...">
    
    <meta property="twitter:image:src" content="http://jimmyjoseph.co.uk/assets/img/">
    

    <!-- Social: Facebook / Open Graph -->
    <meta property="og:url" content="http://jimmyjoseph.co.uk/intelligent-rpa/">
    <meta property="og:title" content="Using ML to filter tasks for RPA">
    
    <meta property="og:image" content="http://jimmyjoseph.co.uk/assets/img/">
    
    <meta property="og:description" content="Not all process are primed for RPA, and this is not black and white. Some process may have counterparts which are automatable. It is a matter of being able t...">
    <meta property="og:site_name" content="Jimmy Joseph">

    <!-- Social: Google+ / Schema.org  -->
    <meta itemprop="name" content="Using ML to filter tasks for RPA"/>
    <meta itemprop="description" content="Not all process are primed for RPA, and this is not black and white. Some process may have counterparts which are automatable. It is a matter of being able t...">
    <meta itemprop="image" content="http://jimmyjoseph.co.uk/assets/img/blog-image.png"/>

    <!-- Favicon -->
    <link rel="shortcut icon" href="/assets/img/icons/favicon.ico" type="image/x-icon" />
    <!-- Apple Touch Icons -->
    <link rel="apple-touch-icon" href="/assets/img/icons/apple-touch-icon.png" />
    <link rel="apple-touch-icon" sizes="57x57" href="/assets/img/icons/apple-touch-icon-57x57.png" />
    <link rel="apple-touch-icon" sizes="72x72" href="/assets/img/icons/apple-touch-icon-72x72.png" />
    <link rel="apple-touch-icon" sizes="114x114" href="/assets/img/icons/apple-touch-icon-114x114.png" />
    <link rel="apple-touch-icon" sizes="144x144" href="/assets/img/icons/apple-touch-icon-144x144.png" />
    <link rel="apple-touch-icon" sizes="60x60" href="/assets/img/icons/apple-touch-icon-60x60.png" />
    <link rel="apple-touch-icon" sizes="120x120" href="/assets/img/icons/apple-touch-icon-120x120.png" />
    <link rel="apple-touch-icon" sizes="76x76" href="/assets/img/icons/apple-touch-icon-76x76.png" />
    <link rel="apple-touch-icon" sizes="152x152" href="/assets/img/icons/apple-touch-icon-152x152.png" />
    <!-- Windows 8 Tile Icons -->
    <meta name="application-name" content="Jimmy Joseph Blog">
    <meta name="msapplication-TileColor" content="#0562DC">
    <meta name="msapplication-square70x70logo" content="smalltile.png" />
    <meta name="msapplication-square150x150logo" content="mediumtile.png" />
    <meta name="msapplication-wide310x150logo" content="widetile.png" />
    <meta name="msapplication-square310x310logo" content="largetile.png" />
    <!-- Android Lolipop Theme Color -->
    <meta name="theme-color" content="#0562DC">

    <link rel="stylesheet" href="/assets/css/main.css">
    <link rel="canonical" href="http://jimmyjoseph.co.uk/intelligent-rpa/">
    <link rel="alternate" type="application/rss+xml" title="Jimmy Joseph" href="http://jimmyjoseph.co.uk/feed.xml" />
</head>


    <body>
        <svg xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" display="none" version="1.1"><defs><symbol id="icon-menu" viewBox="0 0 1024 1024"><path class="path1" d="M128 213.333h768q17.667 0 30.167 12.5t12.5 30.167-12.5 30.167-30.167 12.5h-768q-17.667 0-30.167-12.5t-12.5-30.167 12.5-30.167 30.167-12.5zM128 725.333h768q17.667 0 30.167 12.5t12.5 30.167-12.5 30.167-30.167 12.5h-768q-17.667 0-30.167-12.5t-12.5-30.167 12.5-30.167 30.167-12.5zM128 469.333h768q17.667 0 30.167 12.5t12.5 30.167-12.5 30.167-30.167 12.5h-768q-17.667 0-30.167-12.5t-12.5-30.167 12.5-30.167 30.167-12.5z"/></symbol><symbol id="icon-search" viewBox="0 0 951 1024"><path class="path1" d="M658.286 475.429q0-105.714-75.143-180.857t-180.857-75.143-180.857 75.143-75.143 180.857 75.143 180.857 180.857 75.143 180.857-75.143 75.143-180.857zM950.857 950.857q0 29.714-21.714 51.429t-51.429 21.714q-30.857 0-51.429-21.714l-196-195.429q-102.286 70.857-228 70.857-81.714 0-156.286-31.714t-128.571-85.714-85.714-128.571-31.714-156.286 31.714-156.286 85.714-128.571 128.571-85.714 156.286-31.714 156.286 31.714 128.571 85.714 85.714 128.571 31.714 156.286q0 125.714-70.857 228l196 196q21.143 21.143 21.143 51.429z"/></symbol><symbol id="icon-email" viewBox="0 0 1024 1024"><path class="path1" d="M950.857 859.429v-438.857q-18.286 20.571-39.429 37.714-153.143 117.714-243.429 193.143-29.143 24.571-47.429 38.286t-49.429 27.714-58.571 14h-1.143q-27.429 0-58.571-14t-49.429-27.714-47.429-38.286q-90.286-75.429-243.429-193.143-21.143-17.143-39.429-37.714v438.857q0 7.429 5.429 12.857t12.857 5.429h841.143q7.429 0 12.857-5.429t5.429-12.857zM950.857 258.857v-14t-0.286-7.429-1.714-7.143-3.143-5.143-5.143-4.286-8-1.429h-841.143q-7.429 0-12.857 5.429t-5.429 12.857q0 96 84 162.286 110.286 86.857 229.143 181.143 3.429 2.857 20 16.857t26.286 21.429 25.429 18 28.857 15.714 24.571 5.143h1.143q11.429 0 24.571-5.143t28.857-15.714 25.429-18 26.286-21.429 20-16.857q118.857-94.286 229.143-181.143 30.857-24.571 57.429-66t26.571-75.143zM1024 237.714v621.714q0 37.714-26.857 64.571t-64.571 26.857h-841.143q-37.714 0-64.571-26.857t-26.857-64.571v-621.714q0-37.714 26.857-64.571t64.571-26.857h841.143q37.714 0 64.571 26.857t26.857 64.571z"/></symbol><symbol id="icon-close" viewBox="0 0 805 1024"><path class="path1" d="M741.714 755.429q0 22.857-16 38.857l-77.714 77.714q-16 16-38.857 16t-38.857-16l-168-168-168 168q-16 16-38.857 16t-38.857-16l-77.714-77.714q-16-16-16-38.857t16-38.857l168-168-168-168q-16-16-16-38.857t16-38.857l77.714-77.714q16-16 38.857-16t38.857 16l168 168 168-168q16-16 38.857-16t38.857 16l77.714 77.714q16 16 16 38.857t-16 38.857l-168 168 168 168q16 16 16 38.857z"/></symbol><symbol id="icon-twitter" viewBox="0 0 951 1024"><path class="path1" d="M925.714 233.143q-38.286 56-92.571 95.429 0.571 8 0.571 24 0 74.286-21.714 148.286t-66 142-105.429 120.286-147.429 83.429-184.571 31.143q-154.857 0-283.429-82.857 20 2.286 44.571 2.286 128.571 0 229.143-78.857-60-1.143-107.429-36.857t-65.143-91.143q18.857 2.857 34.857 2.857 24.571 0 48.571-6.286-64-13.143-106-63.714t-42-117.429v-2.286q38.857 21.714 83.429 23.429-37.714-25.143-60-65.714t-22.286-88q0-50.286 25.143-93.143 69.143 85.143 168.286 136.286t212.286 56.857q-4.571-21.714-4.571-42.286 0-76.571 54-130.571t130.571-54q80 0 134.857 58.286 62.286-12 117.143-44.571-21.143 65.714-81.143 101.714 53.143-5.714 106.286-28.571z"/></symbol><symbol id="icon-facebook" viewBox="0 0 585 1024"><path class="path1" d="M548 6.857v150.857h-89.714q-49.143 0-66.286 20.571t-17.143 61.714v108h167.429l-22.286 169.143h-145.143v433.714h-174.857v-433.714h-145.714v-169.143h145.714v-124.571q0-106.286 59.429-164.857t158.286-58.571q84 0 130.286 6.857z"/></symbol><symbol id="icon-rss" viewBox="0 0 805 1024"><path class="path1" d="M219.429 768q0 45.714-32 77.714t-77.714 32-77.714-32-32-77.714 32-77.714 77.714-32 77.714 32 32 77.714zM512 838.286q1.143 16-9.714 27.429-10.286 12-26.857 12h-77.143q-14.286 0-24.571-9.429t-11.429-23.714q-12.571-130.857-105.429-223.714t-223.714-105.429q-14.286-1.143-23.714-11.429t-9.429-24.571v-77.143q0-16.571 12-26.857 9.714-9.714 24.571-9.714h2.857q91.429 7.429 174.857 46t148 103.714q65.143 64.571 103.714 148t46 174.857zM804.571 839.429q1.143 15.429-10.286 26.857-10.286 11.429-26.286 11.429h-81.714q-14.857 0-25.429-10t-11.143-24.286q-6.857-122.857-57.714-233.429t-132.286-192-192-132.286-233.429-58.286q-14.286-0.571-24.286-11.143t-10-24.857v-81.714q0-16 11.429-26.286 10.286-10.286 25.143-10.286h1.714q149.714 7.429 286.571 68.571t243.143 168q106.857 106.286 168 243.143t68.571 286.571z"/></symbol><symbol id="icon-google-plus" viewBox="0 0 951 1024"><path class="path1" d="M420 454.857q0 20.571 18.286 40.286t44.286 38.857 51.714 42 44 59.429 18.286 81.143q0 51.429-27.429 98.857-41.143 69.714-120.571 102.571t-170.286 32.857q-75.429 0-140.857-23.714t-98-78.571q-21.143-34.286-21.143-74.857 0-46.286 25.429-85.714t67.714-65.714q74.857-46.857 230.857-57.143-18.286-24-27.143-42.286t-8.857-41.714q0-20.571 12-48.571-26.286 2.286-38.857 2.286-84.571 0-142.571-55.143t-58-139.714q0-46.857 20.571-90.857t56.571-74.857q44-37.714 104.286-56t124.286-18.286h238.857l-78.857 50.286h-74.857q42.286 36 64 76t21.714 91.429q0 41.143-14 74t-33.714 53.143-39.714 37.143-34 35.143-14 37.714zM336.571 400q21.714 0 44.571-9.429t37.714-24.857q30.286-32.571 30.286-90.857 0-33.143-9.714-71.429t-27.714-74-48.286-59.143-66.857-23.429q-24 0-47.143 11.143t-37.429 30q-26.857 33.714-26.857 91.429 0 26.286 5.714 55.714t18 58.857 29.714 52.857 42.857 38.286 55.143 14.857zM337.714 898.857q33.143 0 63.714-7.429t56.571-22.286 41.714-41.714 15.714-62.286q0-14.286-4-28t-8.286-24-15.429-23.714-16.857-20-22-19.714-20.857-16.571-23.714-17.143-20.857-14.857q-9.143-1.143-27.429-1.143-30.286 0-60 4t-61.429 14.286-55.429 26.286-39.143 42.571-15.429 60.286q0 40 20 70.571t52.286 47.429 68 25.143 72.857 8.286zM800.571 398.286h121.714v61.714h-121.714v125.143h-60v-125.143h-121.143v-61.714h121.143v-124h60v124z"/></symbol><symbol id="icon-angle-down" viewBox="0 0 658 1024"><path class="path1" d="M614.286 420.571q0 7.429-5.714 13.143l-266.286 266.286q-5.714 5.714-13.143 5.714t-13.143-5.714l-266.286-266.286q-5.714-5.714-5.714-13.143t5.714-13.143l28.571-28.571q5.714-5.714 13.143-5.714t13.143 5.714l224.571 224.571 224.571-224.571q5.714-5.714 13.143-5.714t13.143 5.714l28.571 28.571q5.714 5.714 5.714 13.143z"/></symbol><symbol id="icon-github-alt" viewBox="0 0 951 1024"><path class="path1" d="M365.714 694.857q0 22.857-7.143 46.857t-24.571 43.429-41.429 19.429-41.429-19.429-24.571-43.429-7.143-46.857 7.143-46.857 24.571-43.429 41.429-19.429 41.429 19.429 24.571 43.429 7.143 46.857zM731.429 694.857q0 22.857-7.143 46.857t-24.571 43.429-41.429 19.429-41.429-19.429-24.571-43.429-7.143-46.857 7.143-46.857 24.571-43.429 41.429-19.429 41.429 19.429 24.571 43.429 7.143 46.857zM822.857 694.857q0-68.571-39.429-116.571t-106.857-48q-23.429 0-111.429 12-40.571 6.286-89.714 6.286t-89.714-6.286q-86.857-12-111.429-12-67.429 0-106.857 48t-39.429 116.571q0 50.286 18.286 87.714t46.286 58.857 69.714 34.286 80 16.857 85.143 4h96q46.857 0 85.143-4t80-16.857 69.714-34.286 46.286-58.857 18.286-87.714zM950.857 594.286q0 118.286-34.857 189.143-21.714 44-60.286 76t-80.571 49.143-97.143 27.143-98 12.571-95.429 2.571q-44.571 0-81.143-1.714t-84.286-7.143-87.143-17.143-78.286-29.429-69.143-46.286-49.143-65.714q-35.429-70.286-35.429-189.143 0-135.429 77.714-226.286-15.429-46.857-15.429-97.143 0-66.286 29.143-124.571 61.714 0 108.571 22.571t108 70.571q84-20 176.571-20 84.571 0 160 18.286 60-46.857 106.857-69.143t108-22.286q29.143 58.286 29.143 124.571 0 49.714-15.429 96 77.714 91.429 77.714 227.429z"/></symbol></defs></svg>

        <header class="header-post" role="banner">
    <div class="content">
        
            <time itemprop="datePublished" datetime="2020-03-25 12:24:47 +0000" class="date">25 Mar 2020</time>
        
        <h1 class="post-title" itemprop="name">Using ML to filter tasks for RPA</h1>
        <p itemprop="description" class="subtitle">Not all process are primed for RPA, and this is not black and white. Some process may have counterparts which are automatable. It is a matter of being able to cherry pick these cases</p>
    </div>
     <a class="down" data-scroll href="#scroll"><svg class="icon icon-angle-down"><use xlink:href="#icon-angle-down"></use></svg></a>
     <div class="search-wrapper">
    <div class="search-form">
        <input type="text" class="search-field" placeholder="Search...">
        <svg class="icon-remove-sign"><use xlink:href="#icon-close"></use></svg>
        <ul class="search-results search-list"></ul>
    </div>
</div>

<div id="fade" class="overlay"></div>
<a id="slide" class="slideButton fade">
    <svg id="open" class="icon-menu"><use xlink:href="#icon-menu"></use></svg>
    <svg id="close" class="icon-menu"><use xlink:href="#icon-close"></use></svg>
</a>
<aside id="sidebar">
<nav id="navigation">
  <h2>MENU</h2>
  <ul>
    
    
      <li><a href="http://jimmyjoseph.co.uk/">Home</a></li>
    
    
    
      <li><a href="http://jimmyjoseph.co.uk/series">Series</a></li>
    
    
    
      <li><a href="http://jimmyjoseph.co.uk/tags">Tags</a></li>
    
    
    
      <li><a href="http://jimmyjoseph.co.uk/about">About Me</a></li>
    
    
    <li><a class="feed" href="http://jimmyjoseph.co.uk/feed.xml" title="Atom/RSS feed">Feed</a></li>
  </ul>
</nav>
</aside>
<a id="search" class="dosearch">
    <svg class="icon-menu icon-search"><use xlink:href="#icon-search"></use></svg>
</a>

</header>

        <section class="post" itemscope itemtype="http://schema.org/BlogPosting">

            <article role="article" id="scroll" class="post-content" itemprop="articleBody">
                <h1 id="case-scenario">Case Scenario</h1>

<p>It’s 9 AM and Charlie is just getting into the office. Charlie works in a prestiguos Insurance firm. One of her main daily tasks is to look through customer interactions and decide what to do with a case.</p>

<p>When a customer calls up the contact centre employee answering the call makes notes on what was discussed on the call. Notes are automatically added to customer’s account.</p>

<p>Charlie needs to go read each of these notes and decide what to do with these cases. These appear as work items on the system. Some of the options might be:</p>

<ul>
  <li>Send confirmation of insurance cancellation</li>
  <li>Send Policy certificate</li>
  <li>Pass onto Fraud Team</li>
  <li>Pass to Claim Team</li>
  <li>Update Customer’s details on the System</li>
</ul>

<p>Charlie and her team has to 1000’s of notes to go through each day. Most of these notes end in an action that involves a simple action. If an automation was in place to manage the first 4 tasks Charlie and the team can focus on just the updating details.</p>

<p>The first 4 notes rely on reading a <code class="highlighter-rouge">free text</code> box and unfortuantely there is no logical structure on what the call attendant might write here. It’s easy for a human such as Charlie to read and understand what action to take but not rules based enough for a robot.</p>

<p>In this ideal scenario a Machine Learning model can be used as a filter to classify these cases. Once the classification has been done an RPA solution can start processes these cases. Unfortuantely updation of customer details might not be suitable as it will require a high degree of verification and high risk if details include names,address, or bank details.</p>

<p>The task of sending a confirmation of cancellation comes with medium risk and we would want the classification model to have high degree of accuracy. Wrongly issued cancellations will lower customer satisfaction.</p>

<p>The other three tasks such as sending policy certificate, passing the case to different teams comes with low risk as wrongly flagged cases can be salvaged.</p>

<h1 id="code-example">Code Example</h1>

<p>Real company data is not available. But <a href="https://research.google/tools/datasets/taskmaster-1/">Taskmaster-1</a> contains text descriptions of tasks that are generated from conversations.</p>

<p>The machine learning models can be made using python or higher level software such as DataRobot. Before using higher level solutions such as DataRobot it’s a good idea to understand how much effort it will save.</p>

<h3 id="setting-up-the-data">Setting up the Data</h3>
<p>Import Pandas - to build a dataframe for training</p>

<p><code class="highlighter-rouge">re</code> - regular expression, to clean the data later</p>

<p>Load the <code class="highlighter-rouge">.json</code> file and convert it a pandas dataframe <code class="highlighter-rouge">df</code></p>

<figure class="highlight"><pre><code class="language-python" data-lang="python"><span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="n">pd</span>
<span class="kn">import</span> <span class="nn">re</span>
<span class="n">df</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_json</span> <span class="p">(</span><span class="s">r'/home/mandala/Downloads/self-dialogs.json'</span><span class="p">)</span>
<span class="n">df</span><span class="o">.</span><span class="n">keys</span><span class="p">()</span></code></pre></figure>

<h3 id="the-data-has-three-main-parts-here">The Data has three main parts here:</h3>
<ul>
  <li>The conversation ID</li>
  <li>Instruction-ID (target label)</li>
  <li>Utterance (the actual text/conversation)</li>
</ul>

<p>We can peek into the text phrases below. Each conversation is separated into blocks of speech in a script fashion.</p>

<figure class="highlight"><pre><code class="language-python" data-lang="python"><span class="n">df</span><span class="p">[</span><span class="s">"utterances"</span><span class="p">][</span><span class="mi">0</span><span class="p">][</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s">"text"</span><span class="p">)</span></code></pre></figure>

<blockquote>
  <p>“Hi, I’m looking to book a table for Korean fod.”</p>
</blockquote>

<h3 id="cleaning-up">Cleaning up</h3>

<p>The phrases are now stitched into single blocks to make it easier to train. Removing the .json tags we don’t need and using regex to take away anything thats not alpanumeric.</p>

<figure class="highlight"><pre><code class="language-python" data-lang="python"><span class="n">list_of_utterances</span> <span class="o">=</span> <span class="p">[]</span>

<span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span><span class="n">df</span><span class="p">[</span><span class="s">"utterances"</span><span class="p">]</span><span class="o">.</span><span class="n">count</span><span class="p">()):</span>
    <span class="n">text</span> <span class="o">=</span> <span class="s">""</span>
    <span class="n">prelim_list</span> <span class="o">=</span><span class="p">[]</span>
    <span class="k">for</span> <span class="n">j</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span><span class="nb">len</span><span class="p">(</span><span class="n">df</span><span class="p">[</span><span class="s">"utterances"</span><span class="p">][</span><span class="n">i</span><span class="p">])):</span>
        <span class="n">text</span><span class="o">=</span><span class="p">((</span><span class="n">df</span><span class="p">[</span><span class="s">"utterances"</span><span class="p">][</span><span class="n">i</span><span class="p">][</span><span class="n">j</span><span class="p">]</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s">"text"</span><span class="p">)))</span>
        <span class="n">text</span> <span class="o">=</span> <span class="n">text</span><span class="o">.</span><span class="n">lstrip</span><span class="p">()</span>
        <span class="n">text</span> <span class="o">=</span> <span class="n">text</span><span class="o">.</span><span class="n">rstrip</span><span class="p">()</span>
        
        <span class="n">text</span> <span class="o">=</span> <span class="n">re</span><span class="o">.</span><span class="n">sub</span><span class="p">(</span><span class="s">'[^A-Za-z0-9]+'</span><span class="p">,</span> <span class="s">' '</span><span class="p">,</span> <span class="n">text</span><span class="p">)</span> <span class="c">#The filter</span>

        <span class="n">prelim_list</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">text</span><span class="o">+</span><span class="s">' '</span><span class="p">)</span> <span class="c">#adding a space before joining</span>
    <span class="n">list_of_utterances</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="s">''</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">prelim_list</span><span class="p">))</span></code></pre></figure>

<h3 id="visualising-the-text">Visualising the text</h3>
<p>Now we can see a whole conversation with no special characters. Reading over the text extract you have a good idea what the topic of conversation here is.</p>

<figure class="highlight"><pre><code class="language-python" data-lang="python"><span class="k">print</span><span class="p">(</span><span class="n">list_of_utterances</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span></code></pre></figure>

<blockquote>
  <p>Hi I m looking to book a table for Korean fod  Ok what area are you thinking about  Somewhere in Southern NYC maybe the East Village  Ok great There s Thursday Kitchen it has great reviews  That s great So I need a table for tonight at 7 pm for 8 people We don t want to sit at the bar but anywhere else is fine  They don t have any availability for 7 pm  What times are available  5 or 8  Yikes we can t do those times  Ok do you have a second choice  Let me check  Ok  Lets try Boka are they free for 8 people at 7  Yes  Great let s book that  Ok great are there any other requests  No that s it just book  Great should I use your account you have open with them  Yes please  Great You will get a confirmation to your phone soon</p>
</blockquote>

<h3 id="readying-for-training">Readying for training</h3>
<p>Adding the labels and text into a dictionary <code class="highlighter-rouge">d</code> then rewriting the dataframe <code class="highlighter-rouge">df</code>
The several categories can be seen.</p>

<figure class="highlight"><pre><code class="language-python" data-lang="python"><span class="n">d</span> <span class="o">=</span> <span class="p">{</span><span class="s">'instruction_id'</span><span class="p">:</span><span class="n">df</span><span class="p">[</span><span class="s">"instruction_id"</span><span class="p">]</span><span class="o">.</span><span class="n">tolist</span><span class="p">()</span> <span class="p">,</span> <span class="s">'utterance'</span><span class="p">:</span> <span class="n">list_of_utterances</span><span class="p">}</span>
<span class="n">categories</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="nb">set</span><span class="p">(</span><span class="n">df</span><span class="p">[</span><span class="s">"instruction_id"</span><span class="p">]))</span>
<span class="k">print</span><span class="p">(</span><span class="n">categories</span><span class="p">)</span></code></pre></figure>

<blockquote>
  <p>[‘movie-tickets-1’, ‘uber-lyft-1’, ‘restaurant-table-3’, ‘restaurant-table-1’, ‘coffee-ordering-1’, ‘movie-ticket-1’, ‘auto-repair-appt-1’, ‘pizza-ordering-2’, ‘uber-lyft-2’, ‘movie-tickets-3’, ‘pizza-ordering-1’, ‘movie-tickets-2’, ‘coffee-ordering-2’, ‘movie-finder’, ‘restaurant-table-2’]</p>
</blockquote>

<figure class="highlight"><pre><code class="language-python" data-lang="python"><span class="n">df</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">data</span><span class="o">=</span><span class="n">d</span><span class="p">)</span></code></pre></figure>

<p>Some of the labels have number suffix’s. This is because those conversations have been generated using different methods. For our example we just need to classify the text and don’t care about how they were generated so we can take the suffixes out.</p>

<figure class="highlight"><pre><code class="language-python" data-lang="python"><span class="n">df</span><span class="o">.</span><span class="n">replace</span><span class="p">(</span><span class="s">'-</span><span class="err">\</span><span class="s">d+'</span><span class="p">,</span> <span class="s">''</span><span class="p">,</span> <span class="n">regex</span><span class="o">=</span><span class="bp">True</span><span class="p">,</span> <span class="n">inplace</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span><span class="c">#consolidating all like for like labels</span>
<span class="n">df</span><span class="o">.</span><span class="n">replace</span><span class="p">(</span><span class="s">'movie-tickets'</span><span class="p">,</span> <span class="s">'movie-ticket'</span><span class="p">,</span> <span class="n">regex</span><span class="o">=</span><span class="bp">True</span><span class="p">,</span> <span class="n">inplace</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
<span class="n">df</span><span class="p">[</span><span class="s">'instruction_id'</span><span class="p">]</span><span class="o">.</span><span class="n">value_counts</span><span class="p">()</span></code></pre></figure>

<blockquote>
  <p>pizza-ordering      1468</p>

  <p>coffee-ordering     1376</p>

  <p>restaurant-table    1300</p>

  <p>movie-ticket        1251</p>

  <p>auto-repair-appt    1161</p>

  <p>uber-lyft           1098</p>

  <p>movie-finder          54</p>

  <p>Name: instruction_id, dtype: int64</p>
</blockquote>

<p>Dropping <code class="highlighter-rouge">movie-tickets</code> since it has very low volume. A model with a label that has 54 text samples is not good to train with, especially when we have other samples in the thousands.</p>

<figure class="highlight"><pre><code class="language-python" data-lang="python"><span class="n">df</span> <span class="o">=</span> <span class="n">df</span><span class="p">[</span><span class="n">df</span><span class="o">.</span><span class="n">instruction_id</span> <span class="o">!=</span> <span class="s">'movie-finder'</span><span class="p">]</span>
<span class="n">df</span><span class="p">[</span><span class="s">'instruction_id'</span><span class="p">]</span><span class="o">.</span><span class="n">value_counts</span><span class="p">()</span></code></pre></figure>

<blockquote>
  <p>pizza-ordering      1468</p>

  <p>coffee-ordering     1376</p>

  <p>restaurant-table    1300</p>

  <p>movie-ticket        1251</p>

  <p>auto-repair-appt    1161</p>

  <p>uber-lyft           1098</p>

  <p>Name: instruction_id, dtype: int64</p>
</blockquote>

<h3 id="data-is-now-clean--ish">Data is now clean (-ish)</h3>

<p>We’ll be using scikit-learn packages for processing the data.
FIrstly, split into test and train sets. 77% train and 33% test.</p>

<p><img src="/assets/img/IntelAI/SVM1.png" alt="Output" class="img-responsive" /></p>

<p>First we combine the both white and red wine data.</p>

<figure class="highlight"><pre><code class="language-python" data-lang="python"><span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="n">pd</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="n">np</span>

<span class="n">data_red</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_csv</span><span class="p">(</span><span class="s">"winequality-red.csv"</span><span class="p">,</span><span class="n">sep</span><span class="o">=</span><span class="s">';'</span><span class="p">)</span>
<span class="n">data_red</span><span class="p">[</span><span class="s">'color'</span><span class="p">]</span> <span class="o">=</span> <span class="mi">1</span> <span class="c">#redwine</span>

<span class="k">print</span><span class="p">(</span><span class="n">data_red</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>

<span class="n">data_white</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_csv</span><span class="p">(</span><span class="s">"winequality-white.csv"</span><span class="p">,</span><span class="n">sep</span><span class="o">=</span><span class="s">';'</span><span class="p">)</span>
<span class="n">data_white</span><span class="p">[</span><span class="s">'color'</span><span class="p">]</span> <span class="o">=</span> <span class="mi">0</span> <span class="c">#whitewine</span>

<span class="k">print</span><span class="p">(</span><span class="n">data_white</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>

<span class="n">data</span> <span class="o">=</span> <span class="n">data_red</span><span class="o">.</span><span class="n">merge</span><span class="p">(</span><span class="n">data_white</span><span class="p">,</span> <span class="n">how</span><span class="o">=</span><span class="s">'outer'</span><span class="p">)</span>
<span class="n">fields</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="n">data</span><span class="o">.</span><span class="n">columns</span><span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="n">fields</span><span class="p">)</span></code></pre></figure>

<blockquote>
  <ul>
    <li>(1599, 13)</li>
    <li>(4898, 13)</li>
    <li>[‘fixed acidity’, ‘volatile acidity’, ‘citric acid’, ‘residual sugar’, ‘chlorides’, ‘free sulfur dioxide’, ‘total sulfur dioxide’, ‘density’, ‘pH’, ‘sulphates’, ‘alcohol’, ‘quality’, ‘color’]</li>
  </ul>
</blockquote>

<p>Now, lets look at a pairplot to spot any obvious separations.</p>

<figure class="highlight"><pre><code class="language-python" data-lang="python"><span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="n">plt</span>
<span class="kn">import</span> <span class="nn">seaborn</span> <span class="k">as</span> <span class="n">sns</span>

<span class="n">g</span> <span class="o">=</span> <span class="n">sns</span><span class="o">.</span><span class="n">pairplot</span><span class="p">(</span><span class="n">data</span><span class="p">,</span> <span class="n">diag_kind</span><span class="o">=</span><span class="s">'hist'</span><span class="p">,</span><span class="n">hue</span><span class="o">=</span><span class="s">'color'</span><span class="p">)</span></code></pre></figure>

<p><img src="/assets/img/IntelAI/SVM2.png" alt="Output" class="img-responsive" /></p>

<p>There doesn’t seem to be any obvious clusters of wine. Let’s now drop off the non-chemical features.</p>

<figure class="highlight"><pre><code class="language-python" data-lang="python"><span class="n">data</span> <span class="o">=</span> <span class="n">data</span><span class="o">.</span><span class="n">drop</span><span class="p">(</span><span class="n">columns</span><span class="o">=</span><span class="p">[</span><span class="s">'color'</span><span class="p">,</span><span class="s">'quality'</span><span class="p">])</span>
<span class="n">fields</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="n">data</span><span class="o">.</span><span class="n">columns</span><span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="n">fields</span><span class="p">)</span></code></pre></figure>

<blockquote>
  <p>[‘fixed acidity’, ‘volatile acidity’, ‘citric acid’, ‘residual sugar’, ‘chlorides’, ‘free sulfur dioxide’, ‘total sulfur dioxide’, ‘density’, ‘pH’, ‘sulphates’, ‘alcohol’]</p>
</blockquote>

<p>Since we have high-dimensional data(more than 3), Lets see if we can drop some less useful features using using PCA.</p>

<figure class="highlight"><pre><code class="language-python" data-lang="python"><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="n">np</span>
<span class="kn">from</span> <span class="nn">sklearn.decomposition</span> <span class="kn">import</span> <span class="n">PCA</span>
<span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="n">pd</span>
<span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="n">plt</span>
<span class="kn">from</span> <span class="nn">sklearn.preprocessing</span> <span class="kn">import</span> <span class="n">scale</span>
<span class="o">%</span><span class="n">matplotlib</span> <span class="n">inline</span>

<span class="n">X</span> <span class="o">=</span> <span class="n">data</span><span class="p">[</span><span class="n">fields</span><span class="p">]</span>
<span class="n">X</span> <span class="o">=</span> <span class="n">scale</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>

<span class="n">pca</span> <span class="o">=</span> <span class="n">PCA</span><span class="p">(</span><span class="n">n_components</span><span class="o">=</span><span class="mi">11</span><span class="p">)</span>

<span class="n">pca</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>

<span class="n">var</span><span class="o">=</span> <span class="n">pca</span><span class="o">.</span><span class="n">explained_variance_ratio_</span>

<span class="n">var1</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">cumsum</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="nb">round</span><span class="p">(</span><span class="n">pca</span><span class="o">.</span><span class="n">explained_variance_ratio_</span><span class="p">,</span> <span class="n">decimals</span><span class="o">=</span><span class="mi">4</span><span class="p">)</span><span class="o">*</span><span class="mi">100</span><span class="p">)</span>

<span class="k">print</span><span class="p">(</span><span class="n">var1</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">var1</span><span class="p">)</span>

<span class="n">pca</span> <span class="o">=</span> <span class="n">PCA</span><span class="p">(</span><span class="n">n_components</span><span class="o">=</span><span class="mi">9</span><span class="p">)</span>
<span class="n">pca</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>
<span class="n">X1</span><span class="o">=</span><span class="n">pca</span><span class="o">.</span><span class="n">fit_transform</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>

<span class="c">#print(X1)</span></code></pre></figure>

<blockquote>
  <p>[27.54 50.21 64.36 73.18 79.72 85.24 90.   94.56 97.62 99.69 99.99]</p>
</blockquote>

<p><img src="/assets/img/IntelAI/SVM3.png" alt="Output" class="img-responsive" /></p>

<p>The least important feature component still accounts for 28% variance and will not be taken out.</p>

<p>K-means clustering used to cluster the data points and upto 200 clusters were generated iteratevely. We are using silhouette scores (internal validation) to check for compactness and well-separatedness of these clusters.</p>

<p>The average scores for each iterations are then plotted.</p>

<figure class="highlight"><pre><code class="language-python" data-lang="python"><span class="kn">from</span> <span class="nn">sklearn.cluster</span> <span class="kn">import</span> <span class="n">KMeans</span>
<span class="kn">from</span> <span class="nn">sklearn.metrics</span> <span class="kn">import</span> <span class="n">silhouette_samples</span><span class="p">,</span> <span class="n">silhouette_score</span>

<span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="n">plt</span>
<span class="kn">import</span> <span class="nn">matplotlib.cm</span> <span class="k">as</span> <span class="n">cm</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="n">np</span>
<span class="kn">import</span> <span class="nn">itertools</span>

<span class="c">#X = data[fields]</span>

<span class="n">plotx</span> <span class="o">=</span> <span class="p">[]</span>
<span class="n">ploty</span> <span class="o">=</span> <span class="p">[]</span>

<span class="n">plot_dict</span> <span class="o">=</span> <span class="p">{}</span>

<span class="k">for</span> <span class="n">n_clusters</span> <span class="ow">in</span> <span class="nb">range</span> <span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">50</span><span class="p">):</span>

    <span class="n">clusterer</span> <span class="o">=</span> <span class="n">KMeans</span><span class="p">(</span><span class="n">n_clusters</span><span class="o">=</span><span class="n">n_clusters</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">42</span><span class="p">)</span>
    <span class="n">cluster_labels</span> <span class="o">=</span> <span class="n">clusterer</span><span class="o">.</span><span class="n">fit_predict</span><span class="p">(</span><span class="n">X1</span><span class="p">)</span>

    <span class="c"># The silhouette_score gives the average value for all the samples.</span>
    <span class="c"># This gives a perspective into the density and separation of the formed</span>
    <span class="c"># clusters</span>
    <span class="n">silhouette_avg</span> <span class="o">=</span> <span class="n">silhouette_score</span><span class="p">(</span><span class="n">X1</span><span class="p">,</span> <span class="n">cluster_labels</span><span class="p">)</span>
    <span class="n">plotx</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">n_clusters</span><span class="p">)</span>
    <span class="n">ploty</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">silhouette_avg</span><span class="p">)</span>
    
    <span class="n">plot_dict</span><span class="p">[</span><span class="n">n_clusters</span><span class="p">]</span> <span class="o">=</span> <span class="n">silhouette_avg</span>
<span class="c">#     print("For n_clusters =", n_clusters,</span>
<span class="c">#           "The average silhouette_score is :", silhouette_avg)</span>

<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">plotx</span><span class="p">,</span><span class="n">ploty</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s">'no. of clusters'</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s">'avg. silhouette score'</span><span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="s">"number of clusters with the highest avg. silhoutte score is : "</span><span class="o">+</span><span class="nb">str</span><span class="p">(</span><span class="nb">max</span><span class="p">(</span><span class="n">plot_dict</span><span class="o">.</span><span class="n">keys</span><span class="p">(),</span> <span class="n">key</span><span class="o">=</span><span class="k">lambda</span> <span class="n">k</span><span class="p">:</span> <span class="n">plot_dict</span><span class="p">[</span><span class="n">k</span><span class="p">])))</span></code></pre></figure>

<blockquote>
  <p>number of clusters with the highest avg. silhoutte score is : 2
<img src="/assets/img/IntelAI/SVM1.png" alt="Output" class="img-responsive" /></p>
</blockquote>

<h1 id="what-predicts-wine-quality">What predicts wine quality</h1>

<p>A <strong>Pearson correlation</strong> was used to identify which features correlate with wine quality. It looks as if <strong>higher the alcohol content</strong> the <strong>higher the quality</strong>. Lower density and volatile acidity also correlated with better quality as seen in the pairwise correlation chart in Figure 2. Only the top 5 correlated features were carried over to the SVM models.</p>

<p>The figure below shows Pearson Pairwise correlation of features to wine quality.</p>

<p><img src="/assets/img/IntelAI/SVM4.png" alt="Output" class="img-responsive" /></p>

<p>The study by [Cortez et al., 2009] used Support Vector Machines and thus it will be used again to predict the target class, quality. A significant delay was noticed when training SVM’s without normalized data.</p>

<p>After scaling, test and train sets were created(70/30 split). GridSearchCV was used to tune the hyper-parameters of the SVM model. The model’s evaluation is shown below. Two cases are shown, model trained and tested with all the data(model A), and second case omitting qualities with less than 1000 samples(model B) i.e qualities of 5,6,7. Model B achieved better scores than Model A, but can still be improved with more data and expertise.</p>

<p><img src="/assets/img/IntelAI/SVM5.png" alt="Output" class="img-responsive" /></p>

<p>Shown above is the Confusion matrix heat-map of the two different SVM models.</p>

<p><img src="/assets/img/IntelAI/SVM6.png" alt="Output" class="img-responsive" /></p>

<p>Firstly loading and combing both wine data.</p>

<figure class="highlight"><pre><code class="language-python" data-lang="python"><span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="n">pd</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="n">np</span>

<span class="n">data_red</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_csv</span><span class="p">(</span><span class="s">"winequality-red.csv"</span><span class="p">,</span><span class="n">sep</span><span class="o">=</span><span class="s">';'</span><span class="p">)</span>
<span class="n">data_red</span><span class="p">[</span><span class="s">'color'</span><span class="p">]</span> <span class="o">=</span> <span class="mi">1</span> <span class="c">#redwine</span>

<span class="k">print</span><span class="p">(</span><span class="n">data_red</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>

<span class="n">data_white</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_csv</span><span class="p">(</span><span class="s">"winequality-white.csv"</span><span class="p">,</span><span class="n">sep</span><span class="o">=</span><span class="s">';'</span><span class="p">)</span>
<span class="n">data_white</span><span class="p">[</span><span class="s">'color'</span><span class="p">]</span> <span class="o">=</span> <span class="mi">0</span> <span class="c">#whitewine</span>

<span class="k">print</span><span class="p">(</span><span class="n">data_white</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>

<span class="n">data</span> <span class="o">=</span> <span class="n">data_red</span><span class="o">.</span><span class="n">merge</span><span class="p">(</span><span class="n">data_white</span><span class="p">,</span> <span class="n">how</span><span class="o">=</span><span class="s">'outer'</span><span class="p">)</span>


<span class="c">######SUPPRESS_SAMPLES_WITH_VERY_LOW_COUNT####</span>
<span class="n">data</span> <span class="o">=</span> <span class="n">data</span><span class="o">.</span><span class="n">drop</span><span class="p">(</span><span class="n">data</span><span class="p">[</span><span class="n">data</span><span class="o">.</span><span class="n">quality</span> <span class="o">==</span> <span class="mi">9</span><span class="p">]</span><span class="o">.</span><span class="n">index</span><span class="p">)</span>
<span class="n">data</span> <span class="o">=</span> <span class="n">data</span><span class="o">.</span><span class="n">drop</span><span class="p">(</span><span class="n">data</span><span class="p">[</span><span class="n">data</span><span class="o">.</span><span class="n">quality</span> <span class="o">==</span> <span class="mi">3</span><span class="p">]</span><span class="o">.</span><span class="n">index</span><span class="p">)</span>
<span class="n">data</span> <span class="o">=</span> <span class="n">data</span><span class="o">.</span><span class="n">drop</span><span class="p">(</span><span class="n">data</span><span class="p">[</span><span class="n">data</span><span class="o">.</span><span class="n">quality</span> <span class="o">==</span> <span class="mi">8</span><span class="p">]</span><span class="o">.</span><span class="n">index</span><span class="p">)</span>
<span class="n">data</span> <span class="o">=</span> <span class="n">data</span><span class="o">.</span><span class="n">drop</span><span class="p">(</span><span class="n">data</span><span class="p">[</span><span class="n">data</span><span class="o">.</span><span class="n">quality</span> <span class="o">==</span> <span class="mi">4</span><span class="p">]</span><span class="o">.</span><span class="n">index</span><span class="p">)</span>
<span class="c">#data = data.drop(data[data.quality == 7].index)</span></code></pre></figure>

<blockquote>
  <ul>
    <li>(1599, 13)</li>
    <li>(4898, 13)</li>
  </ul>
</blockquote>

<p>There is an imbalance in the datasets, with more than double the samples for white wines. As seen below, there is very low samples for wine qualities of <code class="highlighter-rouge">4,8,3,9</code>, comparing with <code class="highlighter-rouge">6,5,7</code>.</p>

<figure class="highlight"><pre><code class="language-python" data-lang="python"><span class="n">data</span><span class="o">.</span><span class="n">quality</span><span class="o">.</span><span class="n">value_counts</span><span class="p">()</span></code></pre></figure>

<blockquote>
  <ul>
    <li>6    2836</li>
    <li>5    2138</li>
    <li>7    1079</li>
    <li>Name: quality, dtype: int64</li>
  </ul>
</blockquote>

<p>Separating all the features as <code class="highlighter-rouge">X</code>, and the target quality as <code class="highlighter-rouge">y</code>.</p>

<figure class="highlight"><pre><code class="language-python" data-lang="python"><span class="n">fields</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="n">data</span><span class="o">.</span><span class="n">columns</span><span class="p">[:</span><span class="o">-</span><span class="mi">2</span><span class="p">])</span>
<span class="n">fields</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="s">'color'</span><span class="p">)</span><span class="c">#adding color back</span>
<span class="n">X</span> <span class="o">=</span> <span class="n">data</span><span class="p">[</span><span class="n">fields</span><span class="p">]</span>
<span class="n">y</span> <span class="o">=</span> <span class="n">data</span><span class="p">[</span><span class="s">'quality'</span><span class="p">]</span>
<span class="k">print</span><span class="p">(</span><span class="n">fields</span><span class="p">)</span></code></pre></figure>

<blockquote>
  <p>[‘fixed acidity’, ‘volatile acidity’, ‘citric acid’, ‘residual sugar’, ‘chlorides’, ‘free sulfur dioxide’, ‘total sulfur dioxide’, ‘density’, ‘pH’, ‘sulphates’, ‘alcohol’, ‘color’]</p>
</blockquote>

<p>Perfoming pairwise correlation with quality to see which features are highly correlated.</p>

<figure class="highlight"><pre><code class="language-python" data-lang="python"><span class="n">correlations</span> <span class="o">=</span> <span class="n">data</span><span class="p">[</span><span class="n">fields</span><span class="p">]</span><span class="o">.</span><span class="n">corrwith</span><span class="p">(</span><span class="n">y</span><span class="p">)</span>
<span class="n">correlations</span><span class="o">.</span><span class="n">sort_values</span><span class="p">(</span><span class="n">inplace</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>

<span class="n">fields</span> <span class="o">=</span> <span class="n">correlations</span><span class="o">.</span><span class="nb">map</span><span class="p">(</span><span class="nb">abs</span><span class="p">)</span><span class="o">.</span><span class="n">sort_values</span><span class="p">()</span><span class="o">.</span><span class="n">iloc</span><span class="p">[</span><span class="o">-</span><span class="mi">5</span><span class="p">:]</span><span class="o">.</span><span class="n">index</span>
<span class="k">print</span><span class="p">(</span><span class="n">fields</span><span class="p">)</span> <span class="c">#prints the top two abs correlations</span></code></pre></figure>

<blockquote>
  <p>Index([‘color’, ‘chlorides’, ‘volatile acidity’, ‘density’, ‘alcohol’], dtype=’object’)</p>
</blockquote>

<figure class="highlight"><pre><code class="language-python" data-lang="python"><span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="n">plt</span>
<span class="kn">import</span> <span class="nn">seaborn</span> <span class="k">as</span> <span class="n">sns</span>

<span class="n">ax</span> <span class="o">=</span> <span class="n">correlations</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">kind</span><span class="o">=</span><span class="s">'bar'</span><span class="p">)</span>
<span class="n">ax</span><span class="o">.</span><span class="nb">set</span><span class="p">(</span><span class="n">ylim</span><span class="o">=</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">],</span> <span class="n">ylabel</span><span class="o">=</span><span class="s">'pearson correlation'</span><span class="p">)</span></code></pre></figure>

<p><img src="/assets/img/IntelAI/SVM4.png" alt="Output" class="img-responsive" /></p>

<p>Looks like <code class="highlighter-rouge">alcohol</code> and <code class="highlighter-rouge">density</code> are the most correlated with <strong><code class="highlighter-rouge">quality</code></strong>. As per [Cortez et al., 2009], let’s use a SVM to classify wine quality.</p>

<h1 id="svm">SVM</h1>
<p>SVM converges faster when features are scaled. If the model is senstive to magnitudes its generally a good idea to scale so one feature doesn’t get more influence than the other(in terms of scale).</p>

<figure class="highlight"><pre><code class="language-python" data-lang="python"><span class="kn">from</span> <span class="nn">sklearn.preprocessing</span> <span class="kn">import</span> <span class="n">MinMaxScaler</span>

<span class="n">X</span> <span class="o">=</span> <span class="n">data</span><span class="p">[</span><span class="n">fields</span><span class="p">]</span>

<span class="n">scaler</span> <span class="o">=</span> <span class="n">MinMaxScaler</span><span class="p">()</span>
<span class="n">X</span> <span class="o">=</span> <span class="n">scaler</span><span class="o">.</span><span class="n">fit_transform</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>
<span class="n">X</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">columns</span><span class="o">=</span><span class="p">[</span><span class="s">'</span><span class="si">%</span><span class="s">s_scaled'</span> <span class="o">%</span> <span class="n">fld</span> <span class="k">for</span> <span class="n">fld</span> <span class="ow">in</span> <span class="n">fields</span><span class="p">])</span>
<span class="k">print</span><span class="p">(</span><span class="n">X</span><span class="o">.</span><span class="n">columns</span><span class="p">)</span> <span class="c">#scaled columns</span></code></pre></figure>

<blockquote>
  <p>Index([‘color_scaled’, ‘chlorides_scaled’, ‘volatile acidity_scaled’,
       ‘density_scaled’, ‘alcohol_scaled’],
      dtype=’object’)</p>
</blockquote>

<p>Splitting into test and train sets.</p>

<figure class="highlight"><pre><code class="language-python" data-lang="python"><span class="kn">from</span> <span class="nn">sklearn</span> <span class="kn">import</span> <span class="n">svm</span>
<span class="kn">from</span> <span class="nn">sklearn.utils</span> <span class="kn">import</span> <span class="n">shuffle</span>
<span class="kn">from</span> <span class="nn">sklearn.model_selection</span> <span class="kn">import</span> <span class="n">train_test_split</span>
<span class="kn">from</span> <span class="nn">sklearn.model_selection</span> <span class="kn">import</span> <span class="n">GridSearchCV</span>

<span class="n">X_train</span><span class="p">,</span> <span class="n">X_test</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">y_test</span> <span class="o">=</span> <span class="n">train_test_split</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">test_size</span><span class="o">=</span><span class="mf">0.3</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">10</span><span class="p">)</span></code></pre></figure>

<p>GridSearchCV to tune hyperparameters for the SVM.</p>

<figure class="highlight"><pre><code class="language-python" data-lang="python"><span class="n">parameters</span> <span class="o">=</span> <span class="p">{</span><span class="s">'kernel'</span><span class="p">:(</span><span class="s">'linear'</span><span class="p">,</span> <span class="s">'rbf'</span><span class="p">),</span> <span class="s">'C'</span><span class="p">:[</span><span class="o">.</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">10</span><span class="p">],</span> <span class="s">'gamma'</span><span class="p">:[</span><span class="o">.</span><span class="mi">5</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">10</span><span class="p">]}</span>

<span class="n">SVC_Gaussian</span> <span class="o">=</span> <span class="n">svm</span><span class="o">.</span><span class="n">SVC</span><span class="p">(</span><span class="n">gamma</span><span class="o">=</span><span class="s">'scale'</span><span class="p">)</span>
<span class="n">gscv</span> <span class="o">=</span> <span class="n">GridSearchCV</span><span class="p">(</span><span class="n">SVC_Gaussian</span><span class="p">,</span> <span class="n">param_grid</span><span class="o">=</span><span class="n">parameters</span><span class="p">,</span> <span class="n">cv</span><span class="o">=</span><span class="mi">5</span><span class="p">)</span>
<span class="n">gscv</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span></code></pre></figure>

<blockquote>
  <p>GridSearchCV(cv=5, error_score=’raise-deprecating’,
       estimator=SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,
  decision_function_shape=’ovr’, degree=3, gamma=’scale’, kernel=’rbf’,
  max_iter=-1, probability=False, random_state=None, shrinking=True,
  tol=0.001, verbose=False),
       fit_params=None, iid=’warn’, n_jobs=None,
       param_grid={‘kernel’: (‘linear’, ‘rbf’), ‘C’: [0.1, 1, 10], ‘gamma’: [0.5, 1, 2, 10]},
       pre_dispatch=’2*n_jobs’, refit=True, return_train_score=’warn’,
       scoring=None, verbose=0)</p>
</blockquote>

<p>Printing the best parameters.</p>

<figure class="highlight"><pre><code class="language-python" data-lang="python"><span class="k">print</span><span class="p">(</span><span class="n">gscv</span><span class="o">.</span><span class="n">best_estimator_</span><span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="n">gscv</span><span class="o">.</span><span class="n">best_params_</span><span class="p">)</span></code></pre></figure>

<blockquote>
  <p>SVC(C=1, cache_size=200, class_weight=None, coef0=0.0,
  decision_function_shape=’ovr’, degree=3, gamma=10, kernel=’rbf’,
  max_iter=-1, probability=False, random_state=None, shrinking=True,
  tol=0.001, verbose=False)
{‘C’: 1, ‘gamma’: 10, ‘kernel’: ‘rbf’}</p>
</blockquote>

<p>Now we train the SVM model using the above parameters.</p>

<figure class="highlight"><pre><code class="language-python" data-lang="python"><span class="n">SVC_Gaussian</span> <span class="o">=</span> <span class="n">svm</span><span class="o">.</span><span class="n">SVC</span><span class="p">(</span><span class="n">kernel</span><span class="o">=</span><span class="s">'rbf'</span><span class="p">,</span> <span class="n">gamma</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span> <span class="n">C</span><span class="o">=</span><span class="mi">10</span><span class="p">)</span>
<span class="n">SVC_Gaussian</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span></code></pre></figure>

<blockquote>
  <p>SVC(C=10, cache_size=200, class_weight=None, coef0=0.0,
  decision_function_shape=’ovr’, degree=3, gamma=10, kernel=’rbf’,
  max_iter=-1, probability=False, random_state=None, shrinking=True,
  tol=0.001, verbose=False)</p>
</blockquote>

<figure class="highlight"><pre><code class="language-python" data-lang="python"><span class="n">y_pred</span> <span class="o">=</span> <span class="n">SVC_Gaussian</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_test</span><span class="p">)</span></code></pre></figure>

<figure class="highlight"><pre><code class="language-python" data-lang="python"><span class="kn">from</span> <span class="nn">sklearn.metrics</span> <span class="kn">import</span> <span class="n">precision_recall_fscore_support</span> <span class="k">as</span> <span class="n">score</span>
<span class="kn">from</span> <span class="nn">sklearn.metrics</span> <span class="kn">import</span> <span class="n">confusion_matrix</span><span class="p">,</span> <span class="n">accuracy_score</span><span class="p">,</span> <span class="n">roc_auc_score</span>
<span class="kn">from</span> <span class="nn">sklearn.preprocessing</span> <span class="kn">import</span> <span class="n">label_binarize</span>

<span class="n">metrics</span> <span class="o">=</span> <span class="nb">list</span><span class="p">()</span>
<span class="n">cm</span> <span class="o">=</span> <span class="nb">dict</span><span class="p">()</span>


<span class="c"># Preciision, recall, f-score from the multi-class support function</span>
<span class="n">precision</span><span class="p">,</span> <span class="n">recall</span><span class="p">,</span> <span class="n">fscore</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="n">score</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">,</span> <span class="n">average</span><span class="o">=</span><span class="s">'weighted'</span><span class="p">)</span>

<span class="c"># The usual way to calculate accuracy</span>
<span class="n">accuracy</span> <span class="o">=</span> <span class="n">accuracy_score</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">)</span>


<span class="n">metrics</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">pd</span><span class="o">.</span><span class="n">Series</span><span class="p">({</span><span class="s">'precision'</span><span class="p">:</span><span class="n">precision</span><span class="p">,</span> <span class="s">'recall'</span><span class="p">:</span><span class="n">recall</span><span class="p">,</span> 
                          <span class="s">'fscore'</span><span class="p">:</span><span class="n">fscore</span><span class="p">,</span> <span class="s">'accuracy'</span><span class="p">:</span><span class="n">accuracy</span><span class="p">},</span> 
                         <span class="n">name</span><span class="o">=</span><span class="s">'Model'</span><span class="p">))</span>

<span class="n">metrics</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">concat</span><span class="p">(</span><span class="n">metrics</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>

<span class="n">metrics</span></code></pre></figure>

<p><img src="/assets/img/IntelAI/SVM7.png" alt="Output" class="img-responsive" /></p>

<figure class="highlight"><pre><code class="language-python" data-lang="python"><span class="n">y_pred</span> <span class="o">=</span> <span class="n">SVC_Gaussian</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_test</span><span class="p">)</span></code></pre></figure>

<figure class="highlight"><pre><code class="language-python" data-lang="python"><span class="n">y_pred</span>
<span class="c">#y_test</span></code></pre></figure>

<blockquote>
  <p>array([7, 5, 6, …, 5, 6, 5])</p>
</blockquote>

<figure class="highlight"><pre><code class="language-python" data-lang="python"><span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="n">plt</span>


<span class="c"># Last, the confusion matrix</span>
<span class="n">cm</span> <span class="o">=</span> <span class="n">confusion_matrix</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">)</span>

<span class="n">axList</span> <span class="o">=</span> <span class="n">axList</span><span class="o">.</span><span class="n">flatten</span><span class="p">()</span>
<span class="n">fig</span><span class="o">.</span><span class="n">set_size_inches</span><span class="p">(</span><span class="mi">15</span><span class="p">,</span> <span class="mi">15</span><span class="p">)</span>

<span class="n">axList</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">axis</span><span class="p">(</span><span class="s">'off'</span><span class="p">)</span>

<span class="n">plot</span> <span class="o">=</span> <span class="n">sns</span><span class="o">.</span><span class="n">heatmap</span><span class="p">(</span><span class="n">cm</span><span class="p">,</span> <span class="n">annot</span><span class="o">=</span><span class="bp">True</span><span class="p">,</span> <span class="n">fmt</span><span class="o">=</span><span class="s">'d'</span><span class="p">);</span>
    
<span class="n">plt</span><span class="o">.</span><span class="n">tight_layout</span><span class="p">()</span></code></pre></figure>

<p><img src="/assets/img/IntelAI/SVM8.png" alt="Output" class="img-responsive" /></p>

<p>Credits to <a href="https://software.intel.com/en-us/home">Intel AI Academy</a></p>


            </article>

            <section class="share">
    <h3>Share</h3>
    <a aria-label="Share on Twitter" href="https://twitter.com/intent/tweet?text=&quot;&quot;%20http://jimmyjoseph.co.uk/intelligent-rpa/%20via%20&#64;jimmyable_&hashtags=python,rpa,machine learning,business process,sklearn,gridsearchcv,error metrics,tasks,pipeline,"
    onclick="window.open(this.href, 'twitter-share', 'width=550,height=235');return false;" title="Share on Twitter">
        <svg class="icon icon-twitter"><use xlink:href="#icon-twitter"></use></svg>
    </a>
    <a aria-label="Share on Facebook"href="https://www.facebook.com/sharer/sharer.php?u=http://jimmyjoseph.co.uk/intelligent-rpa/"
    onclick="window.open(this.href, 'facebook-share','width=580,height=296');return false;" title="Share on Facebook">
        <svg class="icon icon-facebook"><use xlink:href="#icon-facebook"></use></svg>
    </a>
    <a aria-label="Share on Google Plus" href="https://plus.google.com/share?url=http://jimmyjoseph.co.uk/intelligent-rpa/"
    onclick="window.open(this.href, 'google-plus-share', 'width=490,height=530');return false;" title="Share on Google+">
        <svg class="icon icon-google-plus"><use xlink:href="#icon-google-plus"></use></svg>
    </a>
</section>
            <section class="author" itemprop="author">
    <div class="details" itemscope itemtype="http://schema.org/Person">
        <img itemprop="image" class="img-rounded" src="/assets/img/blog-author.jpg" alt="">
        <p class="def">Author</p>
        <h3 class="name">
            <a itemprop="name" href="http://jimmyjoseph.co.uk/about">Jimmy Joseph</a>
        </h3>
        <p class="desc">Author, Blogger, Computer Scientist, Designer, Engineer...</p>
        <a itemprop="email" class="email" href="mailto:jimmyjoseph@outlook.com">jimmyjoseph@outlook.com</a>
    </div>
</section>

            <!-- <section class="comments">
    <h3>Comments</h3>
    <div id="disqus_thread"></div>
</section>
<script type="text/javascript">
    var disqus_loaded = true;

    function load_disqus()
    {
        disqus_loaded = true;
        var disqus_shortname = '';
        var disqus_title = '';
        var disqus_url = '/intelligent-rpa/';
        var dsq = document.createElement('script'); dsq.type = 'text/javascript'; dsq.async = true;
        dsq.src = '//' + disqus_shortname + '.disqus.com/embed.js';
        (document.getElementsByTagName('head')[0] || document.getElementsByTagName('body')[0]).appendChild(dsq);
        var ldr = document.getElementById('disqus_loader');
    };
    window.onscroll = function(e) {
        if ((window.innerHeight + window.scrollY) >= (document.body.offsetHeight - 800)) {
            //hit bottom of page
            if (disqus_loaded==false)
                load_disqus()
        }
    };
</script>
 -->
            <footer>
    <p>Built with <a href="http://jekyllrb.com/" target="_blank"> Jekyll</a> by <span class="love"></span> <a href="https://willianjusten.com.br">Willian Justen</a></p>
</footer>
<script src="/assets/js/main.js"></script>

        </section>
    </body>
</html>
