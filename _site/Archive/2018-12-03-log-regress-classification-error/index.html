<!DOCTYPE html>
<html lang="pt-br">
    <head>
    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1">

    <title>Logistic Regression and Classification Error Metrics</title>
    <meta name="description" content="In this example we look at correlations, startified shuffle split, and error metrics produced from different cross validation methods. We also look at when w...">

    <!-- Google Authorship Markup -->
    <link rel="author" href="https://plus.google.com/jimmyjoseph1295?rel=author">

    <!-- Social: Twitter -->
    <meta name="twitter:card" content="summary_large_image">
    <meta name="twitter:site" content="@jimmyable_">
    <meta name="twitter:title" content="Logistic Regression and Classification Error Metrics">
    <meta name="twitter:description" content="In this example we look at correlations, startified shuffle split, and error metrics produced from different cross validation methods. We also look at when w...">
    
    <meta property="twitter:image:src" content="http://localhost:4000/assets/img/">
    

    <!-- Social: Facebook / Open Graph -->
    <meta property="og:url" content="http://localhost:4000/Archive/2018-12-03-log-regress-classification-error/">
    <meta property="og:title" content="Logistic Regression and Classification Error Metrics">
    
    <meta property="og:image" content="http://localhost:4000/assets/img/">
    
    <meta property="og:description" content="In this example we look at correlations, startified shuffle split, and error metrics produced from different cross validation methods. We also look at when w...">
    <meta property="og:site_name" content="Jimmy Joseph">

    <!-- Social: Google+ / Schema.org  -->
    <meta itemprop="name" content="Logistic Regression and Classification Error Metrics"/>
    <meta itemprop="description" content="In this example we look at correlations, startified shuffle split, and error metrics produced from different cross validation methods. We also look at when w...">
    <meta itemprop="image" content="http://localhost:4000/assets/img/blog-image.png"/>

    <!-- Favicon -->
    <link rel="shortcut icon" href="/assets/img/icons/favicon.ico" type="image/x-icon" />
    <!-- Apple Touch Icons -->
    <link rel="apple-touch-icon" href="/assets/img/icons/apple-touch-icon.png" />
    <link rel="apple-touch-icon" sizes="57x57" href="/assets/img/icons/apple-touch-icon-57x57.png" />
    <link rel="apple-touch-icon" sizes="72x72" href="/assets/img/icons/apple-touch-icon-72x72.png" />
    <link rel="apple-touch-icon" sizes="114x114" href="/assets/img/icons/apple-touch-icon-114x114.png" />
    <link rel="apple-touch-icon" sizes="144x144" href="/assets/img/icons/apple-touch-icon-144x144.png" />
    <link rel="apple-touch-icon" sizes="60x60" href="/assets/img/icons/apple-touch-icon-60x60.png" />
    <link rel="apple-touch-icon" sizes="120x120" href="/assets/img/icons/apple-touch-icon-120x120.png" />
    <link rel="apple-touch-icon" sizes="76x76" href="/assets/img/icons/apple-touch-icon-76x76.png" />
    <link rel="apple-touch-icon" sizes="152x152" href="/assets/img/icons/apple-touch-icon-152x152.png" />
    <!-- Windows 8 Tile Icons -->
    <meta name="application-name" content="Jimmy Joseph Blog">
    <meta name="msapplication-TileColor" content="#0562DC">
    <meta name="msapplication-square70x70logo" content="smalltile.png" />
    <meta name="msapplication-square150x150logo" content="mediumtile.png" />
    <meta name="msapplication-wide310x150logo" content="widetile.png" />
    <meta name="msapplication-square310x310logo" content="largetile.png" />
    <!-- Android Lolipop Theme Color -->
    <meta name="theme-color" content="#0562DC">

    <link rel="stylesheet" href="/assets/css/main.css">
    <link rel="canonical" href="http://localhost:4000/Archive/2018-12-03-log-regress-classification-error/">
    <link rel="alternate" type="application/rss+xml" title="Jimmy Joseph" href="http://localhost:4000/feed.xml" />
</head>


    <body>
        <svg xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" display="none" version="1.1"><defs><symbol id="icon-menu" viewBox="0 0 1024 1024"><path class="path1" d="M128 213.333h768q17.667 0 30.167 12.5t12.5 30.167-12.5 30.167-30.167 12.5h-768q-17.667 0-30.167-12.5t-12.5-30.167 12.5-30.167 30.167-12.5zM128 725.333h768q17.667 0 30.167 12.5t12.5 30.167-12.5 30.167-30.167 12.5h-768q-17.667 0-30.167-12.5t-12.5-30.167 12.5-30.167 30.167-12.5zM128 469.333h768q17.667 0 30.167 12.5t12.5 30.167-12.5 30.167-30.167 12.5h-768q-17.667 0-30.167-12.5t-12.5-30.167 12.5-30.167 30.167-12.5z"/></symbol><symbol id="icon-search" viewBox="0 0 951 1024"><path class="path1" d="M658.286 475.429q0-105.714-75.143-180.857t-180.857-75.143-180.857 75.143-75.143 180.857 75.143 180.857 180.857 75.143 180.857-75.143 75.143-180.857zM950.857 950.857q0 29.714-21.714 51.429t-51.429 21.714q-30.857 0-51.429-21.714l-196-195.429q-102.286 70.857-228 70.857-81.714 0-156.286-31.714t-128.571-85.714-85.714-128.571-31.714-156.286 31.714-156.286 85.714-128.571 128.571-85.714 156.286-31.714 156.286 31.714 128.571 85.714 85.714 128.571 31.714 156.286q0 125.714-70.857 228l196 196q21.143 21.143 21.143 51.429z"/></symbol><symbol id="icon-email" viewBox="0 0 1024 1024"><path class="path1" d="M950.857 859.429v-438.857q-18.286 20.571-39.429 37.714-153.143 117.714-243.429 193.143-29.143 24.571-47.429 38.286t-49.429 27.714-58.571 14h-1.143q-27.429 0-58.571-14t-49.429-27.714-47.429-38.286q-90.286-75.429-243.429-193.143-21.143-17.143-39.429-37.714v438.857q0 7.429 5.429 12.857t12.857 5.429h841.143q7.429 0 12.857-5.429t5.429-12.857zM950.857 258.857v-14t-0.286-7.429-1.714-7.143-3.143-5.143-5.143-4.286-8-1.429h-841.143q-7.429 0-12.857 5.429t-5.429 12.857q0 96 84 162.286 110.286 86.857 229.143 181.143 3.429 2.857 20 16.857t26.286 21.429 25.429 18 28.857 15.714 24.571 5.143h1.143q11.429 0 24.571-5.143t28.857-15.714 25.429-18 26.286-21.429 20-16.857q118.857-94.286 229.143-181.143 30.857-24.571 57.429-66t26.571-75.143zM1024 237.714v621.714q0 37.714-26.857 64.571t-64.571 26.857h-841.143q-37.714 0-64.571-26.857t-26.857-64.571v-621.714q0-37.714 26.857-64.571t64.571-26.857h841.143q37.714 0 64.571 26.857t26.857 64.571z"/></symbol><symbol id="icon-close" viewBox="0 0 805 1024"><path class="path1" d="M741.714 755.429q0 22.857-16 38.857l-77.714 77.714q-16 16-38.857 16t-38.857-16l-168-168-168 168q-16 16-38.857 16t-38.857-16l-77.714-77.714q-16-16-16-38.857t16-38.857l168-168-168-168q-16-16-16-38.857t16-38.857l77.714-77.714q16-16 38.857-16t38.857 16l168 168 168-168q16-16 38.857-16t38.857 16l77.714 77.714q16 16 16 38.857t-16 38.857l-168 168 168 168q16 16 16 38.857z"/></symbol><symbol id="icon-twitter" viewBox="0 0 951 1024"><path class="path1" d="M925.714 233.143q-38.286 56-92.571 95.429 0.571 8 0.571 24 0 74.286-21.714 148.286t-66 142-105.429 120.286-147.429 83.429-184.571 31.143q-154.857 0-283.429-82.857 20 2.286 44.571 2.286 128.571 0 229.143-78.857-60-1.143-107.429-36.857t-65.143-91.143q18.857 2.857 34.857 2.857 24.571 0 48.571-6.286-64-13.143-106-63.714t-42-117.429v-2.286q38.857 21.714 83.429 23.429-37.714-25.143-60-65.714t-22.286-88q0-50.286 25.143-93.143 69.143 85.143 168.286 136.286t212.286 56.857q-4.571-21.714-4.571-42.286 0-76.571 54-130.571t130.571-54q80 0 134.857 58.286 62.286-12 117.143-44.571-21.143 65.714-81.143 101.714 53.143-5.714 106.286-28.571z"/></symbol><symbol id="icon-facebook" viewBox="0 0 585 1024"><path class="path1" d="M548 6.857v150.857h-89.714q-49.143 0-66.286 20.571t-17.143 61.714v108h167.429l-22.286 169.143h-145.143v433.714h-174.857v-433.714h-145.714v-169.143h145.714v-124.571q0-106.286 59.429-164.857t158.286-58.571q84 0 130.286 6.857z"/></symbol><symbol id="icon-rss" viewBox="0 0 805 1024"><path class="path1" d="M219.429 768q0 45.714-32 77.714t-77.714 32-77.714-32-32-77.714 32-77.714 77.714-32 77.714 32 32 77.714zM512 838.286q1.143 16-9.714 27.429-10.286 12-26.857 12h-77.143q-14.286 0-24.571-9.429t-11.429-23.714q-12.571-130.857-105.429-223.714t-223.714-105.429q-14.286-1.143-23.714-11.429t-9.429-24.571v-77.143q0-16.571 12-26.857 9.714-9.714 24.571-9.714h2.857q91.429 7.429 174.857 46t148 103.714q65.143 64.571 103.714 148t46 174.857zM804.571 839.429q1.143 15.429-10.286 26.857-10.286 11.429-26.286 11.429h-81.714q-14.857 0-25.429-10t-11.143-24.286q-6.857-122.857-57.714-233.429t-132.286-192-192-132.286-233.429-58.286q-14.286-0.571-24.286-11.143t-10-24.857v-81.714q0-16 11.429-26.286 10.286-10.286 25.143-10.286h1.714q149.714 7.429 286.571 68.571t243.143 168q106.857 106.286 168 243.143t68.571 286.571z"/></symbol><symbol id="icon-google-plus" viewBox="0 0 951 1024"><path class="path1" d="M420 454.857q0 20.571 18.286 40.286t44.286 38.857 51.714 42 44 59.429 18.286 81.143q0 51.429-27.429 98.857-41.143 69.714-120.571 102.571t-170.286 32.857q-75.429 0-140.857-23.714t-98-78.571q-21.143-34.286-21.143-74.857 0-46.286 25.429-85.714t67.714-65.714q74.857-46.857 230.857-57.143-18.286-24-27.143-42.286t-8.857-41.714q0-20.571 12-48.571-26.286 2.286-38.857 2.286-84.571 0-142.571-55.143t-58-139.714q0-46.857 20.571-90.857t56.571-74.857q44-37.714 104.286-56t124.286-18.286h238.857l-78.857 50.286h-74.857q42.286 36 64 76t21.714 91.429q0 41.143-14 74t-33.714 53.143-39.714 37.143-34 35.143-14 37.714zM336.571 400q21.714 0 44.571-9.429t37.714-24.857q30.286-32.571 30.286-90.857 0-33.143-9.714-71.429t-27.714-74-48.286-59.143-66.857-23.429q-24 0-47.143 11.143t-37.429 30q-26.857 33.714-26.857 91.429 0 26.286 5.714 55.714t18 58.857 29.714 52.857 42.857 38.286 55.143 14.857zM337.714 898.857q33.143 0 63.714-7.429t56.571-22.286 41.714-41.714 15.714-62.286q0-14.286-4-28t-8.286-24-15.429-23.714-16.857-20-22-19.714-20.857-16.571-23.714-17.143-20.857-14.857q-9.143-1.143-27.429-1.143-30.286 0-60 4t-61.429 14.286-55.429 26.286-39.143 42.571-15.429 60.286q0 40 20 70.571t52.286 47.429 68 25.143 72.857 8.286zM800.571 398.286h121.714v61.714h-121.714v125.143h-60v-125.143h-121.143v-61.714h121.143v-124h60v124z"/></symbol><symbol id="icon-angle-down" viewBox="0 0 658 1024"><path class="path1" d="M614.286 420.571q0 7.429-5.714 13.143l-266.286 266.286q-5.714 5.714-13.143 5.714t-13.143-5.714l-266.286-266.286q-5.714-5.714-5.714-13.143t5.714-13.143l28.571-28.571q5.714-5.714 13.143-5.714t13.143 5.714l224.571 224.571 224.571-224.571q5.714-5.714 13.143-5.714t13.143 5.714l28.571 28.571q5.714 5.714 5.714 13.143z"/></symbol><symbol id="icon-github-alt" viewBox="0 0 951 1024"><path class="path1" d="M365.714 694.857q0 22.857-7.143 46.857t-24.571 43.429-41.429 19.429-41.429-19.429-24.571-43.429-7.143-46.857 7.143-46.857 24.571-43.429 41.429-19.429 41.429 19.429 24.571 43.429 7.143 46.857zM731.429 694.857q0 22.857-7.143 46.857t-24.571 43.429-41.429 19.429-41.429-19.429-24.571-43.429-7.143-46.857 7.143-46.857 24.571-43.429 41.429-19.429 41.429 19.429 24.571 43.429 7.143 46.857zM822.857 694.857q0-68.571-39.429-116.571t-106.857-48q-23.429 0-111.429 12-40.571 6.286-89.714 6.286t-89.714-6.286q-86.857-12-111.429-12-67.429 0-106.857 48t-39.429 116.571q0 50.286 18.286 87.714t46.286 58.857 69.714 34.286 80 16.857 85.143 4h96q46.857 0 85.143-4t80-16.857 69.714-34.286 46.286-58.857 18.286-87.714zM950.857 594.286q0 118.286-34.857 189.143-21.714 44-60.286 76t-80.571 49.143-97.143 27.143-98 12.571-95.429 2.571q-44.571 0-81.143-1.714t-84.286-7.143-87.143-17.143-78.286-29.429-69.143-46.286-49.143-65.714q-35.429-70.286-35.429-189.143 0-135.429 77.714-226.286-15.429-46.857-15.429-97.143 0-66.286 29.143-124.571 61.714 0 108.571 22.571t108 70.571q84-20 176.571-20 84.571 0 160 18.286 60-46.857 106.857-69.143t108-22.286q29.143 58.286 29.143 124.571 0 49.714-15.429 96 77.714 91.429 77.714 227.429z"/></symbol></defs></svg>

        <header class="header-post" role="banner">
    <div class="content">
        
            <time itemprop="datePublished" datetime="2018-12-03 10:28:47 +0000" class="date">03 Dec 2018</time>
        
        <h1 class="post-title" itemprop="name">Logistic Regression and Classification Error Metrics</h1>
        <p itemprop="description" class="subtitle">In this example we look at correlations, startified shuffle split, and error metrics produced from different cross validation methods. We also look at when we remove highly correlated columns.</p>
    </div>
     <a class="down" data-scroll href="#scroll"><svg class="icon icon-angle-down"><use xlink:href="#icon-angle-down"></use></svg></a>
     <div class="search-wrapper">
    <div class="search-form">
        <input type="text" class="search-field" placeholder="Search...">
        <svg class="icon-remove-sign"><use xlink:href="#icon-close"></use></svg>
        <ul class="search-results search-list"></ul>
    </div>
</div>

<div id="fade" class="overlay"></div>
<a id="slide" class="slideButton fade">
    <svg id="open" class="icon-menu"><use xlink:href="#icon-menu"></use></svg>
    <svg id="close" class="icon-menu"><use xlink:href="#icon-close"></use></svg>
</a>
<aside id="sidebar">
<nav id="navigation">
  <h2>MENU</h2>
  <ul>
    
    
      <li><a href="http://localhost:4000/">Home</a></li>
    
    
    
      <li><a href="http://localhost:4000/series">Series</a></li>
    
    
    
      <li><a href="http://localhost:4000/tags">Tags</a></li>
    
    
    
      <li><a href="http://localhost:4000/about">About Me</a></li>
    
    
    <li><a class="feed" href="http://localhost:4000/feed.xml" title="Atom/RSS feed">Feed</a></li>
  </ul>
</nav>
</aside>
<a id="search" class="dosearch">
    <svg class="icon-menu icon-search"><use xlink:href="#icon-search"></use></svg>
</a>

</header>

        <section class="post" itemscope itemtype="http://schema.org/BlogPosting">

            <article role="article" id="scroll" class="post-content" itemprop="articleBody">
                <h1 id="logistic-regression-and-classification-error-metrics">Logistic Regression and Classification Error Metrics</h1>

<p>In this worked example, we use <a href="https://archive.ics.uci.edu/ml/datasets/Human+Activity+Recognition+Using+Smartphones">Human Activity Recognition with Smartphones</a> database, which was built from the recordings of study participants performing activities of daily living (ADL) while carrying a smartphone with an embedded inertial sensors. The objective is to classify activities into one of the six activities (walking, walking upstairs, walking downstairs, sitting, standing, and laying) performed.</p>

<p>For each record in the dataset it is provided:</p>

<ul>
  <li>Triaxial acceleration from the accelerometer (total acceleration) and the estimated body acceleration.</li>
  <li>Triaxial Angular velocity from the gyroscope.</li>
  <li>A 561-feature vector with time and frequency domain variables.</li>
  <li>Its activity label.</li>
</ul>

<p>Now, lets import the dataset.</p>

<figure class="highlight"><pre><code class="language-python" data-lang="python"><span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="n">pd</span><span class="p">,</span> <span class="n">numpy</span> <span class="k">as</span> <span class="n">np</span>

<span class="n">data</span> <span class="o">=</span> <span class="n">pd</span><span class="p">.</span><span class="n">read_csv</span><span class="p">(</span><span class="s">'/data/Human_Activity_Recognition_Using_Smartphones_Data.csv'</span><span class="p">)</span></code></pre></figure>

<p>The data columns are all floats except for the activity label.</p>

<figure class="highlight"><pre><code class="language-python" data-lang="python"><span class="n">data</span><span class="p">.</span><span class="n">dtypes</span><span class="p">.</span><span class="n">value_counts</span><span class="p">()</span></code></pre></figure>

<blockquote>
  <ul>
    <li>float64    561</li>
    <li>object       1</li>
    <li>dtype: int64</li>
  </ul>
</blockquote>

<figure class="highlight"><pre><code class="language-python" data-lang="python"><span class="n">data</span><span class="p">.</span><span class="n">dtypes</span><span class="p">.</span><span class="n">tail</span><span class="p">()</span></code></pre></figure>

<blockquote>
  <ul>
    <li>angle(tBodyGyroJerkMean,gravityMean)    float64</li>
    <li>angle(X,gravityMean)                    float64</li>
    <li>angle(Y,gravityMean)                    float64</li>
    <li>angle(Z,gravityMean)                    float64</li>
    <li>Activity                                 object</li>
    <li>dtype: object</li>
  </ul>
</blockquote>

<p>The data are all scaled from -1 (minimum) to 1.0 (maximum).</p>

<figure class="highlight"><pre><code class="language-python" data-lang="python"><span class="n">data</span><span class="p">.</span><span class="n">iloc</span><span class="p">[:,</span> <span class="p">:</span><span class="o">-</span><span class="mi">1</span><span class="p">].</span><span class="nb">min</span><span class="p">().</span><span class="n">value_counts</span><span class="p">()</span></code></pre></figure>

<blockquote>
  <ul>
    <li>-1.0    561</li>
    <li>dtype: int64</li>
  </ul>
</blockquote>

<figure class="highlight"><pre><code class="language-python" data-lang="python"><span class="n">data</span><span class="p">.</span><span class="n">iloc</span><span class="p">[:,</span> <span class="p">:</span><span class="o">-</span><span class="mi">1</span><span class="p">].</span><span class="nb">max</span><span class="p">().</span><span class="n">value_counts</span><span class="p">()</span></code></pre></figure>

<blockquote>
  <ul>
    <li>1.0    561</li>
    <li>dtype: int64</li>
  </ul>
</blockquote>

<p>Examine the breakdown of activities–they are relatively balanced.</p>

<figure class="highlight"><pre><code class="language-python" data-lang="python"><span class="n">data</span><span class="p">.</span><span class="n">Activity</span><span class="p">.</span><span class="n">value_counts</span><span class="p">()</span></code></pre></figure>

<blockquote>
  <ul>
    <li>LAYING                1944</li>
    <li>STANDING              1906</li>
    <li>SITTING               1777</li>
    <li>WALKING               1722</li>
    <li>WALKING_UPSTAIRS      1544</li>
    <li>WALKING_DOWNSTAIRS    1406</li>
    <li>Name: Activity, dtype: int64</li>
  </ul>
</blockquote>

<p>Since Scikit-learn doesn’t accept sparse matrix for the prediction columns we will use <code class="highlighter-rouge">LabelEncoder</code> to convert activity labels into integers. Lets try and look at the values.</p>

<figure class="highlight"><pre><code class="language-python" data-lang="python"><span class="kn">from</span> <span class="nn">sklearn.preprocessing</span> <span class="kn">import</span> <span class="n">LabelEncoder</span>

<span class="n">le</span> <span class="o">=</span> <span class="n">LabelEncoder</span><span class="p">()</span>
<span class="n">data</span><span class="p">[</span><span class="s">'Activity'</span><span class="p">]</span> <span class="o">=</span> <span class="n">le</span><span class="p">.</span><span class="n">fit_transform</span><span class="p">(</span><span class="n">data</span><span class="p">.</span><span class="n">Activity</span><span class="p">)</span>
<span class="n">data</span><span class="p">[</span><span class="s">'Activity'</span><span class="p">].</span><span class="n">sample</span><span class="p">(</span><span class="mi">5</span><span class="p">)</span></code></pre></figure>

<blockquote>
  <ul>
    <li>5944    0</li>
    <li>3473    1</li>
    <li>3114    1</li>
    <li>4753    1</li>
    <li>2959    0</li>
    <li>Name: Activity, dtype: int64</li>
  </ul>
</blockquote>

<h1 id="correlations">Correlations</h1>

<p>We are going to calculate the correlations between the dependent variables.</p>

<figure class="highlight"><pre><code class="language-python" data-lang="python"><span class="c1"># Calculate the correlation values
</span><span class="n">feature_cols</span> <span class="o">=</span> <span class="n">data</span><span class="p">.</span><span class="n">columns</span><span class="p">[:</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span>
<span class="n">corr_values</span> <span class="o">=</span> <span class="n">data</span><span class="p">[</span><span class="n">feature_cols</span><span class="p">].</span><span class="n">corr</span><span class="p">()</span>

<span class="c1">#Simplify by emptying all the data below the diagonal
</span><span class="n">tril_index</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">tril_indices_from</span><span class="p">(</span><span class="n">corr_values</span><span class="p">)</span>

<span class="c1">#Make the unused values NaNs
</span><span class="k">for</span> <span class="n">coord</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="o">*</span><span class="n">tril_index</span><span class="p">):</span>
    <span class="n">corr_values</span><span class="p">.</span><span class="n">iloc</span><span class="p">[</span><span class="n">coord</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">coord</span><span class="p">[</span><span class="mi">1</span><span class="p">]]</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">NaN</span>

<span class="c1">#Stack the data and convert to a data frame
</span><span class="n">corr_values</span> <span class="o">=</span> <span class="p">(</span><span class="n">corr_values</span><span class="p">.</span><span class="n">stack</span><span class="p">().</span><span class="n">to_frame</span><span class="p">().</span><span class="n">reset_index</span><span class="p">().</span><span class="n">rename</span><span class="p">(</span><span class="n">columns</span><span class="o">=</span><span class="p">{</span><span class="s">'level_0'</span><span class="p">:</span><span class="s">'feature1'</span><span class="p">,</span><span class="s">'level1'</span><span class="p">:</span><span class="s">'feature2'</span><span class="p">,</span><span class="mi">0</span><span class="p">:</span><span class="s">'correlation'</span><span class="p">}))</span>

<span class="c1">#Get the absolute values for sorting
</span><span class="n">corr_values</span><span class="p">[</span><span class="s">'abs_correlation'</span><span class="p">]</span> <span class="o">=</span> <span class="n">corr_values</span><span class="p">.</span><span class="n">correlation</span><span class="p">.</span><span class="nb">abs</span><span class="p">()</span></code></pre></figure>

<p>Visualising the absolute value correlations using a histogram.</p>

<figure class="highlight"><pre><code class="language-python" data-lang="python"><span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="n">plt</span>
<span class="kn">import</span> <span class="nn">seaborn</span> <span class="k">as</span> <span class="n">sns</span>

<span class="n">sns</span><span class="p">.</span><span class="n">set_context</span><span class="p">(</span><span class="s">'talk'</span><span class="p">)</span>
<span class="n">sns</span><span class="p">.</span><span class="n">set_style</span><span class="p">(</span><span class="s">'white'</span><span class="p">)</span>
<span class="n">sns</span><span class="p">.</span><span class="n">set_palette</span><span class="p">(</span><span class="s">'dark'</span><span class="p">)</span>

<span class="n">ax</span> <span class="o">=</span> <span class="n">corr_values</span><span class="p">.</span><span class="n">abs_correlation</span><span class="p">.</span><span class="n">hist</span><span class="p">(</span><span class="n">bins</span><span class="o">=</span><span class="mi">50</span><span class="p">)</span>

<span class="n">ax</span><span class="p">.</span><span class="nb">set</span><span class="p">(</span><span class="n">xlabel</span><span class="o">=</span><span class="s">'Absolute Correlation'</span><span class="p">,</span> <span class="n">ylabel</span><span class="o">=</span><span class="s">'Frequency'</span><span class="p">);</span></code></pre></figure>

<p><img src="/assets/img/IntelAI/logError1.png" alt="Output" class="img-responsive" /></p>

<p>The most highly correlated values:</p>

<figure class="highlight"><pre><code class="language-python" data-lang="python"><span class="n">corr_values</span><span class="p">.</span><span class="n">sort_values</span><span class="p">(</span><span class="s">'correlation'</span><span class="p">,</span> <span class="n">ascending</span><span class="o">=</span><span class="bp">False</span><span class="p">).</span><span class="n">query</span><span class="p">(</span><span class="s">'abs_correlation&gt;0.8'</span><span class="p">)</span></code></pre></figure>

<p><img src="/assets/img/IntelAI/logError2.png" alt="Output" class="img-responsive" /></p>

<h1 id="stratified-shuffle-split">Stratified Shuffle Split</h1>
<p>We will now split the data into test and train sets. There are lots of methods available but Scikit-learn’s <code class="highlighter-rouge">StratifiedShuffleSplit</code> is used now. This type of split maintains the same ratio of predictor classes.</p>

<figure class="highlight"><pre><code class="language-python" data-lang="python"><span class="kn">from</span> <span class="nn">sklearn.model_selection</span> <span class="kn">import</span> <span class="n">StratifiedShuffleSplit</span>

<span class="c1"># Get the split indices
# Test size - 30%
</span><span class="n">strat_shuf_split</span> <span class="o">=</span> <span class="n">StratifiedShuffleSplit</span><span class="p">(</span><span class="n">n_splits</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span><span class="n">test_size</span><span class="o">=</span><span class="mf">0.3</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">42</span><span class="p">)</span>

<span class="n">train_idx</span><span class="p">,</span> <span class="n">test_idx</span> <span class="o">=</span> <span class="nb">next</span><span class="p">(</span><span class="n">strat_shuf_split</span><span class="p">.</span><span class="n">split</span><span class="p">(</span><span class="n">data</span><span class="p">[</span><span class="n">feature_cols</span><span class="p">],</span> <span class="n">data</span><span class="p">.</span><span class="n">Activity</span><span class="p">))</span>

<span class="c1"># Create the dataframes
</span><span class="n">X_train</span> <span class="o">=</span> <span class="n">data</span><span class="p">.</span><span class="n">loc</span><span class="p">[</span><span class="n">train_idx</span><span class="p">,</span> <span class="n">feature_cols</span><span class="p">]</span>
<span class="n">y_train</span> <span class="o">=</span> <span class="n">data</span><span class="p">.</span><span class="n">loc</span><span class="p">[</span><span class="n">train_idx</span><span class="p">,</span> <span class="s">'Activity'</span><span class="p">]</span>

<span class="n">X_test</span>  <span class="o">=</span> <span class="n">data</span><span class="p">.</span><span class="n">loc</span><span class="p">[</span><span class="n">test_idx</span><span class="p">,</span> <span class="n">feature_cols</span><span class="p">]</span>
<span class="n">y_test</span>  <span class="o">=</span> <span class="n">data</span><span class="p">.</span><span class="n">loc</span><span class="p">[</span><span class="n">test_idx</span><span class="p">,</span> <span class="s">'Activity'</span><span class="p">]</span></code></pre></figure>

<p>Regardless of methods used to split the data, compare the ratio of classes in both the train and test splits.</p>

<figure class="highlight"><pre><code class="language-python" data-lang="python"><span class="n">y_train</span><span class="p">.</span><span class="n">value_counts</span><span class="p">(</span><span class="n">normalize</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span></code></pre></figure>

<blockquote>
  <ul>
    <li>0    0.188792</li>
    <li>2    0.185046</li>
    <li>1    0.172562</li>
    <li>3    0.167152</li>
    <li>5    0.149951</li>
    <li>4    0.136496</li>
    <li>Name: Activity, dtype: float64</li>
  </ul>
</blockquote>

<figure class="highlight"><pre><code class="language-python" data-lang="python"><span class="n">y_test</span><span class="p">.</span><span class="n">value_counts</span><span class="p">(</span><span class="n">normalize</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span></code></pre></figure>

<blockquote>
  <ul>
    <li>0    0.188673</li>
    <li>2    0.185113</li>
    <li>1    0.172492</li>
    <li>3    0.167314</li>
    <li>5    0.149838</li>
    <li>4    0.136570</li>
    <li>Name: Activity, dtype: float64</li>
  </ul>
</blockquote>

<h1 id="logistic-regression">Logistic Regression</h1>
<p>We are going to fit multi-class model using all the features with no regularization.</p>

<figure class="highlight"><pre><code class="language-python" data-lang="python"><span class="kn">from</span> <span class="nn">sklearn.linear_model</span> <span class="kn">import</span> <span class="n">LogisticRegression</span>

<span class="c1"># Standard logistic regression
</span><span class="n">lr</span> <span class="o">=</span> <span class="n">LogisticRegression</span><span class="p">().</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span></code></pre></figure>

<p>Using cross validation to determine the hyperparameters, fit models using <strong>L1</strong>, and <strong>L2</strong> regularization. Store each of these models as well. Note the limitations on multi-class models, solvers, and regularizations. The regularized models, in particular the L1 model, will probably take a while to fit.</p>

<p>Different solvers that can be used are:</p>
<ul>
  <li><code class="highlighter-rouge">liblinear</code></li>
  <li><code class="highlighter-rouge">newton-cg</code></li>
  <li><code class="highlighter-rouge">lbfgs</code></li>
  <li><code class="highlighter-rouge">sag</code></li>
  <li><code class="highlighter-rouge">saga</code></li>
</ul>

<figure class="highlight"><pre><code class="language-python" data-lang="python"><span class="kn">from</span> <span class="nn">sklearn.linear_model</span> <span class="kn">import</span> <span class="n">LogisticRegressionCV</span>

<span class="c1"># L1 regularized logistic regression
</span><span class="n">lr_l1</span> <span class="o">=</span> <span class="n">LogisticRegressionCV</span><span class="p">(</span><span class="n">Cs</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span> <span class="n">cv</span><span class="o">=</span><span class="mi">4</span><span class="p">,</span> <span class="n">penalty</span><span class="o">=</span><span class="s">'l1'</span><span class="p">,</span> <span class="n">solver</span><span class="o">=</span><span class="s">'liblinear'</span><span class="p">).</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>

<span class="c1"># L2 regularized logistic regression
</span><span class="n">lr_l2</span> <span class="o">=</span> <span class="n">LogisticRegressionCV</span><span class="p">(</span><span class="n">Cs</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span> <span class="n">cv</span><span class="o">=</span><span class="mi">4</span><span class="p">,</span> <span class="n">penalty</span><span class="o">=</span><span class="s">'l2'</span><span class="p">).</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span></code></pre></figure>

<h1 id="coefficients">Coefficients</h1>
<p>For each of the models lets compare the magnitude of the coefficients.</p>

<figure class="highlight"><pre><code class="language-python" data-lang="python"><span class="c1"># Combine all the coefficients into a dataframe
</span><span class="n">coefficients</span> <span class="o">=</span> <span class="nb">list</span><span class="p">()</span>

<span class="n">coeff_labels</span> <span class="o">=</span> <span class="p">[</span><span class="s">'lr'</span><span class="p">,</span> <span class="s">'l1'</span><span class="p">,</span> <span class="s">'l2'</span><span class="p">]</span>
<span class="n">coeff_models</span> <span class="o">=</span> <span class="p">[</span><span class="n">lr</span><span class="p">,</span> <span class="n">lr_l1</span><span class="p">,</span> <span class="n">lr_l2</span><span class="p">]</span>

<span class="k">for</span> <span class="n">lab</span><span class="p">,</span><span class="n">mod</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="n">coeff_labels</span><span class="p">,</span> <span class="n">coeff_models</span><span class="p">):</span>
    <span class="n">coeffs</span> <span class="o">=</span> <span class="n">mod</span><span class="p">.</span><span class="n">coef_</span>
    <span class="n">coeff_label</span> <span class="o">=</span> <span class="n">pd</span><span class="p">.</span><span class="n">MultiIndex</span><span class="p">(</span><span class="n">levels</span><span class="o">=</span><span class="p">[[</span><span class="n">lab</span><span class="p">],</span> <span class="p">[</span><span class="mi">0</span><span class="p">,</span><span class="mi">1</span><span class="p">,</span><span class="mi">2</span><span class="p">,</span><span class="mi">3</span><span class="p">,</span><span class="mi">4</span><span class="p">,</span><span class="mi">5</span><span class="p">]],</span> 
                                 <span class="n">labels</span><span class="o">=</span><span class="p">[[</span><span class="mi">0</span><span class="p">,</span><span class="mi">0</span><span class="p">,</span><span class="mi">0</span><span class="p">,</span><span class="mi">0</span><span class="p">,</span><span class="mi">0</span><span class="p">,</span><span class="mi">0</span><span class="p">],</span> <span class="p">[</span><span class="mi">0</span><span class="p">,</span><span class="mi">1</span><span class="p">,</span><span class="mi">2</span><span class="p">,</span><span class="mi">3</span><span class="p">,</span><span class="mi">4</span><span class="p">,</span><span class="mi">5</span><span class="p">]])</span>
    <span class="n">coefficients</span><span class="p">.</span><span class="n">append</span><span class="p">(</span><span class="n">pd</span><span class="p">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">coeffs</span><span class="p">.</span><span class="n">T</span><span class="p">,</span> <span class="n">columns</span><span class="o">=</span><span class="n">coeff_label</span><span class="p">))</span>

<span class="n">coefficients</span> <span class="o">=</span> <span class="n">pd</span><span class="p">.</span><span class="n">concat</span><span class="p">(</span><span class="n">coefficients</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>

<span class="n">coefficients</span><span class="p">.</span><span class="n">head</span><span class="p">()</span></code></pre></figure>

<p><img src="/assets/img/IntelAI/logError3.png" alt="Output" class="img-responsive" /></p>

<p>Now let’s plot six seperate plots for each of the multi-class coefficients.</p>

<figure class="highlight"><pre><code class="language-python" data-lang="python"><span class="n">fig</span><span class="p">,</span> <span class="n">axList</span> <span class="o">=</span> <span class="n">plt</span><span class="p">.</span><span class="n">subplots</span><span class="p">(</span><span class="n">nrows</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span> <span class="n">ncols</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>
<span class="n">axList</span> <span class="o">=</span> <span class="n">axList</span><span class="p">.</span><span class="n">flatten</span><span class="p">()</span>
<span class="n">fig</span><span class="p">.</span><span class="n">set_size_inches</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span><span class="mi">10</span><span class="p">)</span>


<span class="k">for</span> <span class="n">ax</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">axList</span><span class="p">):</span>
    <span class="n">loc</span> <span class="o">=</span> <span class="n">ax</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
    <span class="n">ax</span> <span class="o">=</span> <span class="n">ax</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span>
    
    <span class="n">data</span> <span class="o">=</span> <span class="n">coefficients</span><span class="p">.</span><span class="n">xs</span><span class="p">(</span><span class="n">loc</span><span class="p">,</span> <span class="n">level</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
    <span class="n">data</span><span class="p">.</span><span class="n">plot</span><span class="p">(</span><span class="n">marker</span><span class="o">=</span><span class="s">'o'</span><span class="p">,</span> <span class="n">ls</span><span class="o">=</span><span class="s">''</span><span class="p">,</span> <span class="n">ms</span><span class="o">=</span><span class="mf">4.0</span><span class="p">,</span> <span class="n">ax</span><span class="o">=</span><span class="n">ax</span><span class="p">,</span> <span class="n">legend</span><span class="o">=</span><span class="bp">False</span><span class="p">)</span>
    
    <span class="k">if</span> <span class="n">ax</span> <span class="ow">is</span> <span class="n">axList</span><span class="p">[</span><span class="mi">0</span><span class="p">]:</span>
        <span class="n">ax</span><span class="p">.</span><span class="n">legend</span><span class="p">(</span><span class="n">loc</span><span class="o">=</span><span class="mi">4</span><span class="p">)</span>
        
    <span class="n">ax</span><span class="p">.</span><span class="nb">set</span><span class="p">(</span><span class="n">title</span><span class="o">=</span><span class="s">'Coefficient Set '</span><span class="o">+</span><span class="nb">str</span><span class="p">(</span><span class="n">loc</span><span class="p">))</span>

<span class="n">plt</span><span class="p">.</span><span class="n">tight_layout</span><span class="p">()</span></code></pre></figure>

<h1 id="probability-prediction">Probability Prediction</h1>
<p>Lets predict and store the class for each model. We will also store the probability for the predictions of classes for each model.</p>

<figure class="highlight"><pre><code class="language-python" data-lang="python"><span class="c1"># Predict the class and the probability for each
</span>
<span class="n">y_pred</span> <span class="o">=</span> <span class="nb">list</span><span class="p">()</span>
<span class="n">y_prob</span> <span class="o">=</span> <span class="nb">list</span><span class="p">()</span>

<span class="n">coeff_labels</span> <span class="o">=</span> <span class="p">[</span><span class="s">'lr'</span><span class="p">,</span> <span class="s">'l1'</span><span class="p">,</span> <span class="s">'l2'</span><span class="p">]</span>
<span class="n">coeff_models</span> <span class="o">=</span> <span class="p">[</span><span class="n">lr</span><span class="p">,</span> <span class="n">lr_l1</span><span class="p">,</span> <span class="n">lr_l2</span><span class="p">]</span>

<span class="k">for</span> <span class="n">lab</span><span class="p">,</span><span class="n">mod</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="n">coeff_labels</span><span class="p">,</span> <span class="n">coeff_models</span><span class="p">):</span>
    <span class="n">y_pred</span><span class="p">.</span><span class="n">append</span><span class="p">(</span><span class="n">pd</span><span class="p">.</span><span class="n">Series</span><span class="p">(</span><span class="n">mod</span><span class="p">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_test</span><span class="p">),</span> <span class="n">name</span><span class="o">=</span><span class="n">lab</span><span class="p">))</span>
    <span class="n">y_prob</span><span class="p">.</span><span class="n">append</span><span class="p">(</span><span class="n">pd</span><span class="p">.</span><span class="n">Series</span><span class="p">(</span><span class="n">mod</span><span class="p">.</span><span class="n">predict_proba</span><span class="p">(</span><span class="n">X_test</span><span class="p">).</span><span class="nb">max</span><span class="p">(</span><span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">),</span> <span class="n">name</span><span class="o">=</span><span class="n">lab</span><span class="p">))</span>
    
<span class="n">y_pred</span> <span class="o">=</span> <span class="n">pd</span><span class="p">.</span><span class="n">concat</span><span class="p">(</span><span class="n">y_pred</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
<span class="n">y_prob</span> <span class="o">=</span> <span class="n">pd</span><span class="p">.</span><span class="n">concat</span><span class="p">(</span><span class="n">y_prob</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>

<span class="n">y_pred</span><span class="p">.</span><span class="n">head</span><span class="p">()</span></code></pre></figure>

<p><img src="/assets/img/IntelAI/logError4.png" alt="Output" class="img-responsive" /></p>

<figure class="highlight"><pre><code class="language-python" data-lang="python"><span class="c1"># Predict the class and the probability for each
</span>
<span class="n">y_pred</span> <span class="o">=</span> <span class="nb">list</span><span class="p">()</span>
<span class="n">y_prob</span> <span class="o">=</span> <span class="nb">list</span><span class="p">()</span>

<span class="n">coeff_labels</span> <span class="o">=</span> <span class="p">[</span><span class="s">'lr'</span><span class="p">,</span> <span class="s">'l1'</span><span class="p">,</span> <span class="s">'l2'</span><span class="p">]</span>
<span class="n">coeff_models</span> <span class="o">=</span> <span class="p">[</span><span class="n">lr</span><span class="p">,</span> <span class="n">lr_l1</span><span class="p">,</span> <span class="n">lr_l2</span><span class="p">]</span>

<span class="k">for</span> <span class="n">lab</span><span class="p">,</span><span class="n">mod</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="n">coeff_labels</span><span class="p">,</span> <span class="n">coeff_models</span><span class="p">):</span>
    <span class="n">y_pred</span><span class="p">.</span><span class="n">append</span><span class="p">(</span><span class="n">pd</span><span class="p">.</span><span class="n">Series</span><span class="p">(</span><span class="n">mod</span><span class="p">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_test</span><span class="p">),</span> <span class="n">name</span><span class="o">=</span><span class="n">lab</span><span class="p">))</span>
    <span class="n">y_prob</span><span class="p">.</span><span class="n">append</span><span class="p">(</span><span class="n">pd</span><span class="p">.</span><span class="n">Series</span><span class="p">(</span><span class="n">mod</span><span class="p">.</span><span class="n">predict_proba</span><span class="p">(</span><span class="n">X_test</span><span class="p">).</span><span class="nb">max</span><span class="p">(</span><span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">),</span> <span class="n">name</span><span class="o">=</span><span class="n">lab</span><span class="p">))</span>
    
<span class="n">y_pred</span> <span class="o">=</span> <span class="n">pd</span><span class="p">.</span><span class="n">concat</span><span class="p">(</span><span class="n">y_pred</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
<span class="n">y_prob</span> <span class="o">=</span> <span class="n">pd</span><span class="p">.</span><span class="n">concat</span><span class="p">(</span><span class="n">y_prob</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>

<span class="n">y_pred</span><span class="p">.</span><span class="n">head</span><span class="p">()</span></code></pre></figure>

<p><img src="/assets/img/IntelAI/logError5.png" alt="Output" class="img-responsive" /></p>

<h1 id="error-metrics">Error metrics</h1>
<p>Lets now calculate error metrics for each model. We will need to combine multi-class metrics into a single value for each model.</p>

<ul>
  <li>accuracy</li>
  <li>precision</li>
  <li>recall</li>
  <li>fscore</li>
  <li>confusion matrix</li>
</ul>

<figure class="highlight"><pre><code class="language-python" data-lang="python"><span class="kn">from</span> <span class="nn">sklearn.metrics</span> <span class="kn">import</span> <span class="n">precision_recall_fscore_support</span> <span class="k">as</span> <span class="n">score</span>
<span class="kn">from</span> <span class="nn">sklearn.metrics</span> <span class="kn">import</span> <span class="n">confusion_matrix</span><span class="p">,</span> <span class="n">accuracy_score</span><span class="p">,</span> <span class="n">roc_auc_score</span>
<span class="kn">from</span> <span class="nn">sklearn.preprocessing</span> <span class="kn">import</span> <span class="n">label_binarize</span>

<span class="n">metrics</span> <span class="o">=</span> <span class="nb">list</span><span class="p">()</span>
<span class="n">cm</span> <span class="o">=</span> <span class="nb">dict</span><span class="p">()</span>

<span class="k">for</span> <span class="n">lab</span> <span class="ow">in</span> <span class="n">coeff_labels</span><span class="p">:</span>

    <span class="c1"># Preciision, recall, f-score from the multi-class support function
</span>    <span class="n">precision</span><span class="p">,</span> <span class="n">recall</span><span class="p">,</span> <span class="n">fscore</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="n">score</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">[</span><span class="n">lab</span><span class="p">],</span> <span class="n">average</span><span class="o">=</span><span class="s">'weighted'</span><span class="p">)</span>
    
    <span class="c1"># The usual way to calculate accuracy
</span>    <span class="n">accuracy</span> <span class="o">=</span> <span class="n">accuracy_score</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">[</span><span class="n">lab</span><span class="p">])</span>
    
    <span class="c1"># ROC-AUC scores can be calculated by binarizing the data
</span>    <span class="n">auc</span> <span class="o">=</span> <span class="n">roc_auc_score</span><span class="p">(</span><span class="n">label_binarize</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span> <span class="n">classes</span><span class="o">=</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span><span class="mi">1</span><span class="p">,</span><span class="mi">2</span><span class="p">,</span><span class="mi">3</span><span class="p">,</span><span class="mi">4</span><span class="p">,</span><span class="mi">5</span><span class="p">]),</span>
              <span class="n">label_binarize</span><span class="p">(</span><span class="n">y_pred</span><span class="p">[</span><span class="n">lab</span><span class="p">],</span> <span class="n">classes</span><span class="o">=</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span><span class="mi">1</span><span class="p">,</span><span class="mi">2</span><span class="p">,</span><span class="mi">3</span><span class="p">,</span><span class="mi">4</span><span class="p">,</span><span class="mi">5</span><span class="p">]),</span> 
              <span class="n">average</span><span class="o">=</span><span class="s">'weighted'</span><span class="p">)</span>
    
    <span class="c1"># Last, the confusion matrix
</span>    <span class="n">cm</span><span class="p">[</span><span class="n">lab</span><span class="p">]</span> <span class="o">=</span> <span class="n">confusion_matrix</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">[</span><span class="n">lab</span><span class="p">])</span>
    
    <span class="n">metrics</span><span class="p">.</span><span class="n">append</span><span class="p">(</span><span class="n">pd</span><span class="p">.</span><span class="n">Series</span><span class="p">({</span><span class="s">'precision'</span><span class="p">:</span><span class="n">precision</span><span class="p">,</span> <span class="s">'recall'</span><span class="p">:</span><span class="n">recall</span><span class="p">,</span> 
                              <span class="s">'fscore'</span><span class="p">:</span><span class="n">fscore</span><span class="p">,</span> <span class="s">'accuracy'</span><span class="p">:</span><span class="n">accuracy</span><span class="p">,</span>
                              <span class="s">'auc'</span><span class="p">:</span><span class="n">auc</span><span class="p">},</span> 
                             <span class="n">name</span><span class="o">=</span><span class="n">lab</span><span class="p">))</span>

<span class="n">metrics</span> <span class="o">=</span> <span class="n">pd</span><span class="p">.</span><span class="n">concat</span><span class="p">(</span><span class="n">metrics</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>

<span class="n">metrics</span></code></pre></figure>

<p><img src="/assets/img/IntelAI/logError6.png" alt="Output" class="img-responsive" /></p>

<h1 id="confusion-matrix">Confusion Matrix</h1>
<p>Plotting the confusion matric for each model.</p>

<figure class="highlight"><pre><code class="language-python" data-lang="python"><span class="n">fig</span><span class="p">,</span> <span class="n">axList</span> <span class="o">=</span> <span class="n">plt</span><span class="p">.</span><span class="n">subplots</span><span class="p">(</span><span class="n">nrows</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">ncols</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>
<span class="n">axList</span> <span class="o">=</span> <span class="n">axList</span><span class="p">.</span><span class="n">flatten</span><span class="p">()</span>
<span class="n">fig</span><span class="p">.</span><span class="n">set_size_inches</span><span class="p">(</span><span class="mi">12</span><span class="p">,</span> <span class="mi">10</span><span class="p">)</span>

<span class="n">axList</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">].</span><span class="n">axis</span><span class="p">(</span><span class="s">'off'</span><span class="p">)</span>

<span class="k">for</span> <span class="n">ax</span><span class="p">,</span><span class="n">lab</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="n">axList</span><span class="p">[:</span><span class="o">-</span><span class="mi">1</span><span class="p">],</span> <span class="n">coeff_labels</span><span class="p">):</span>
    <span class="n">sns</span><span class="p">.</span><span class="n">heatmap</span><span class="p">(</span><span class="n">cm</span><span class="p">[</span><span class="n">lab</span><span class="p">],</span> <span class="n">ax</span><span class="o">=</span><span class="n">ax</span><span class="p">,</span> <span class="n">annot</span><span class="o">=</span><span class="bp">True</span><span class="p">,</span> <span class="n">fmt</span><span class="o">=</span><span class="s">'d'</span><span class="p">);</span>
    <span class="n">ax</span><span class="p">.</span><span class="nb">set</span><span class="p">(</span><span class="n">title</span><span class="o">=</span><span class="n">lab</span><span class="p">);</span>
    
<span class="n">plt</span><span class="p">.</span><span class="n">tight_layout</span><span class="p">()</span></code></pre></figure>

<p><img src="/assets/img/IntelAI/logError7.png" alt="Output" class="img-responsive" /></p>

<h1 id="removing-highly-correlated-columns">Removing Highly Correlated columns</h1>
<p>Identifying and then removing the highly correlated columns.</p>

<p>Correlated features in general don’t improve models. For linear models (e.g., linear regression or logistic regression), multicolinearity can yield solutions that are wildly varying and possibly numerically unstable. <a href="https://datascience.stackexchange.com/questions/24452/in-supervised-learning-why-is-it-bad-to-have-correlated-features">Read More…</a></p>

<figure class="highlight"><pre><code class="language-python" data-lang="python"><span class="kn">from</span> <span class="nn">sklearn.feature_selection</span> <span class="kn">import</span> <span class="n">SelectKBest</span>
<span class="kn">from</span> <span class="nn">sklearn.feature_selection</span> <span class="kn">import</span> <span class="n">chi2</span>
<span class="kn">from</span> <span class="nn">sklearn.feature_selection</span> <span class="kn">import</span> <span class="n">VarianceThreshold</span>

<span class="c1">#threshold with .7
</span>
<span class="n">sel</span> <span class="o">=</span> <span class="n">VarianceThreshold</span><span class="p">(</span><span class="n">threshold</span><span class="o">=</span><span class="p">(.</span><span class="mi">7</span> <span class="o">*</span> <span class="p">(</span><span class="mi">1</span> <span class="o">-</span> <span class="p">.</span><span class="mi">7</span><span class="p">)))</span>

<span class="n">data2</span> <span class="o">=</span> <span class="n">pd</span><span class="p">.</span><span class="n">concat</span><span class="p">([</span><span class="n">X_train</span><span class="p">,</span><span class="n">X_test</span><span class="p">])</span>
<span class="n">data_new</span> <span class="o">=</span> <span class="n">pd</span><span class="p">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">sel</span><span class="p">.</span><span class="n">fit_transform</span><span class="p">(</span><span class="n">data2</span><span class="p">))</span>


<span class="n">data_y</span> <span class="o">=</span> <span class="n">pd</span><span class="p">.</span><span class="n">concat</span><span class="p">([</span><span class="n">y_train</span><span class="p">,</span><span class="n">y_test</span><span class="p">])</span>

<span class="kn">from</span> <span class="nn">sklearn.model_selection</span> <span class="kn">import</span> <span class="n">train_test_split</span>

<span class="n">X_new</span><span class="p">,</span><span class="n">X_test_new</span> <span class="o">=</span> <span class="n">train_test_split</span><span class="p">(</span><span class="n">data_new</span><span class="p">)</span>
<span class="n">Y_new</span><span class="p">,</span><span class="n">Y_test_new</span> <span class="o">=</span> <span class="n">train_test_split</span><span class="p">(</span><span class="n">data_y</span><span class="p">)</span></code></pre></figure>

<p>We are going to repeat the model building using the data with removed correlated columns.</p>

<p>Using <strong>L1</strong> and <strong>L2</strong> logistic regression.</p>

<figure class="highlight"><pre><code class="language-python" data-lang="python"><span class="kn">from</span> <span class="nn">sklearn.linear_model</span> <span class="kn">import</span> <span class="n">LogisticRegression</span>

<span class="c1"># Standard logistic regression
</span><span class="n">lr</span> <span class="o">=</span> <span class="n">LogisticRegression</span><span class="p">().</span><span class="n">fit</span><span class="p">(</span><span class="n">X_new</span><span class="p">,</span> <span class="n">Y_new</span><span class="p">)</span>

<span class="kn">from</span> <span class="nn">sklearn.linear_model</span> <span class="kn">import</span> <span class="n">LogisticRegressionCV</span>

<span class="c1"># L1 regularized logistic regression
</span><span class="n">lr_l1</span> <span class="o">=</span> <span class="n">LogisticRegressionCV</span><span class="p">(</span><span class="n">Cs</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span> <span class="n">cv</span><span class="o">=</span><span class="mi">4</span><span class="p">,</span> <span class="n">penalty</span><span class="o">=</span><span class="s">'l1'</span><span class="p">,</span> <span class="n">solver</span><span class="o">=</span><span class="s">'liblinear'</span><span class="p">).</span><span class="n">fit</span><span class="p">(</span><span class="n">X_new</span><span class="p">,</span> <span class="n">Y_new</span><span class="p">)</span>

<span class="c1"># L2 regularized logistic regression
</span><span class="n">lr_l2</span> <span class="o">=</span> <span class="n">LogisticRegressionCV</span><span class="p">(</span><span class="n">Cs</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span> <span class="n">cv</span><span class="o">=</span><span class="mi">4</span><span class="p">,</span> <span class="n">penalty</span><span class="o">=</span><span class="s">'l2'</span><span class="p">).</span><span class="n">fit</span><span class="p">(</span><span class="n">X_new</span><span class="p">,</span> <span class="n">Y_new</span><span class="p">)</span></code></pre></figure>

<h1 id="comparing-coefficients">Comparing Coefficients</h1>
<p>Compare the magnitudes of the coefficients for each of the models. If one-vs-rest fitting was used, each set of coefficients can be plotted separately.</p>

<figure class="highlight"><pre><code class="language-python" data-lang="python"><span class="c1"># Combine all the coefficients into a dataframe
</span><span class="n">coefficients</span><span class="p">.</span><span class="n">sample</span><span class="p">(</span><span class="mi">10</span><span class="p">)</span>
<span class="n">coefficients</span> <span class="o">=</span> <span class="nb">list</span><span class="p">()</span>

<span class="n">coeff_labels</span> <span class="o">=</span> <span class="p">[</span><span class="s">'lr'</span><span class="p">,</span> <span class="s">'l1'</span><span class="p">,</span> <span class="s">'l2'</span><span class="p">]</span>
<span class="n">coeff_models</span> <span class="o">=</span> <span class="p">[</span><span class="n">lr</span><span class="p">,</span> <span class="n">lr_l1</span><span class="p">,</span> <span class="n">lr_l2</span><span class="p">]</span>

<span class="k">for</span> <span class="n">lab</span><span class="p">,</span><span class="n">mod</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="n">coeff_labels</span><span class="p">,</span> <span class="n">coeff_models</span><span class="p">):</span>
    <span class="n">coeffs</span> <span class="o">=</span> <span class="n">mod</span><span class="p">.</span><span class="n">coef_</span>
    <span class="n">coeff_label</span> <span class="o">=</span> <span class="n">pd</span><span class="p">.</span><span class="n">MultiIndex</span><span class="p">(</span><span class="n">levels</span><span class="o">=</span><span class="p">[[</span><span class="n">lab</span><span class="p">],</span> <span class="p">[</span><span class="mi">0</span><span class="p">,</span><span class="mi">1</span><span class="p">,</span><span class="mi">2</span><span class="p">,</span><span class="mi">3</span><span class="p">,</span><span class="mi">4</span><span class="p">,</span><span class="mi">5</span><span class="p">]],</span> 
                                 <span class="n">labels</span><span class="o">=</span><span class="p">[[</span><span class="mi">0</span><span class="p">,</span><span class="mi">0</span><span class="p">,</span><span class="mi">0</span><span class="p">,</span><span class="mi">0</span><span class="p">,</span><span class="mi">0</span><span class="p">,</span><span class="mi">0</span><span class="p">],</span> <span class="p">[</span><span class="mi">0</span><span class="p">,</span><span class="mi">1</span><span class="p">,</span><span class="mi">2</span><span class="p">,</span><span class="mi">3</span><span class="p">,</span><span class="mi">4</span><span class="p">,</span><span class="mi">5</span><span class="p">]])</span>
    <span class="n">coefficients</span><span class="p">.</span><span class="n">append</span><span class="p">(</span><span class="n">pd</span><span class="p">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">coeffs</span><span class="p">.</span><span class="n">T</span><span class="p">,</span> <span class="n">columns</span><span class="o">=</span><span class="n">coeff_label</span><span class="p">))</span>

<span class="n">coefficients</span> <span class="o">=</span> <span class="n">pd</span><span class="p">.</span><span class="n">concat</span><span class="p">(</span><span class="n">coefficients</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>

<span class="n">coefficients</span><span class="p">.</span><span class="n">head</span><span class="p">()</span></code></pre></figure>

<p><img src="/assets/img/IntelAI/logError8.png" alt="Output" class="img-responsive" /></p>

<h1 id="plotting-the-coefficients">Plotting the coefficients</h1>
<p>Let’s look at the plots for the each of the multi-class coefficients.</p>

<figure class="highlight"><pre><code class="language-python" data-lang="python"><span class="n">fig</span><span class="p">,</span> <span class="n">axList</span> <span class="o">=</span> <span class="n">plt</span><span class="p">.</span><span class="n">subplots</span><span class="p">(</span><span class="n">nrows</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span> <span class="n">ncols</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>
<span class="n">axList</span> <span class="o">=</span> <span class="n">axList</span><span class="p">.</span><span class="n">flatten</span><span class="p">()</span>
<span class="n">fig</span><span class="p">.</span><span class="n">set_size_inches</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span><span class="mi">10</span><span class="p">)</span>


<span class="k">for</span> <span class="n">ax</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">axList</span><span class="p">):</span>
    <span class="n">loc</span> <span class="o">=</span> <span class="n">ax</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
    <span class="n">ax</span> <span class="o">=</span> <span class="n">ax</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span>
    
    <span class="n">data</span> <span class="o">=</span> <span class="n">coefficients</span><span class="p">.</span><span class="n">xs</span><span class="p">(</span><span class="n">loc</span><span class="p">,</span> <span class="n">level</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
    <span class="n">data</span><span class="p">.</span><span class="n">plot</span><span class="p">(</span><span class="n">marker</span><span class="o">=</span><span class="s">'o'</span><span class="p">,</span> <span class="n">ls</span><span class="o">=</span><span class="s">''</span><span class="p">,</span> <span class="n">ms</span><span class="o">=</span><span class="mf">4.0</span><span class="p">,</span> <span class="n">ax</span><span class="o">=</span><span class="n">ax</span><span class="p">,</span> <span class="n">legend</span><span class="o">=</span><span class="bp">False</span><span class="p">)</span>
    
    <span class="k">if</span> <span class="n">ax</span> <span class="ow">is</span> <span class="n">axList</span><span class="p">[</span><span class="mi">0</span><span class="p">]:</span>
        <span class="n">ax</span><span class="p">.</span><span class="n">legend</span><span class="p">(</span><span class="n">loc</span><span class="o">=</span><span class="mi">4</span><span class="p">)</span>
        
    <span class="n">ax</span><span class="p">.</span><span class="nb">set</span><span class="p">(</span><span class="n">title</span><span class="o">=</span><span class="s">'Coefficient Set '</span><span class="o">+</span><span class="nb">str</span><span class="p">(</span><span class="n">loc</span><span class="p">))</span>

<span class="n">plt</span><span class="p">.</span><span class="n">tight_layout</span><span class="p">()</span></code></pre></figure>

<p><img src="/assets/img/IntelAI/logError9.png" alt="Output" class="img-responsive" /></p>

<p>The points are much more consolidated this time around.</p>

<h1 id="prediction-of-class-probability">Prediction of class probability</h1>
<p>We are now going to predict and store the class for each model.
We will also store the probability for predicted classes for each model.</p>

<figure class="highlight"><pre><code class="language-python" data-lang="python"><span class="c1"># Predict the class and the probability for each
</span>
<span class="n">y_pred</span> <span class="o">=</span> <span class="nb">list</span><span class="p">()</span>
<span class="n">y_prob</span> <span class="o">=</span> <span class="nb">list</span><span class="p">()</span>

<span class="n">coeff_labels</span> <span class="o">=</span> <span class="p">[</span><span class="s">'lr'</span><span class="p">,</span> <span class="s">'l1'</span><span class="p">,</span> <span class="s">'l2'</span><span class="p">]</span>
<span class="n">coeff_models</span> <span class="o">=</span> <span class="p">[</span><span class="n">lr</span><span class="p">,</span> <span class="n">lr_l1</span><span class="p">,</span> <span class="n">lr_l2</span><span class="p">]</span>

<span class="k">for</span> <span class="n">lab</span><span class="p">,</span><span class="n">mod</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="n">coeff_labels</span><span class="p">,</span> <span class="n">coeff_models</span><span class="p">):</span>
    <span class="n">y_pred</span><span class="p">.</span><span class="n">append</span><span class="p">(</span><span class="n">pd</span><span class="p">.</span><span class="n">Series</span><span class="p">(</span><span class="n">mod</span><span class="p">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_test_new</span><span class="p">),</span> <span class="n">name</span><span class="o">=</span><span class="n">lab</span><span class="p">))</span>
    <span class="n">y_prob</span><span class="p">.</span><span class="n">append</span><span class="p">(</span><span class="n">pd</span><span class="p">.</span><span class="n">Series</span><span class="p">(</span><span class="n">mod</span><span class="p">.</span><span class="n">predict_proba</span><span class="p">(</span><span class="n">X_test_new</span><span class="p">).</span><span class="nb">max</span><span class="p">(</span><span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">),</span> <span class="n">name</span><span class="o">=</span><span class="n">lab</span><span class="p">))</span>
    
<span class="n">y_pred</span> <span class="o">=</span> <span class="n">pd</span><span class="p">.</span><span class="n">concat</span><span class="p">(</span><span class="n">y_pred</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
<span class="n">y_prob</span> <span class="o">=</span> <span class="n">pd</span><span class="p">.</span><span class="n">concat</span><span class="p">(</span><span class="n">y_prob</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>

<span class="n">y_pred</span><span class="p">.</span><span class="n">head</span><span class="p">()</span></code></pre></figure>

<p><img src="/assets/img/IntelAI/logError10.png" alt="Output" class="img-responsive" /></p>

<figure class="highlight"><pre><code class="language-python" data-lang="python"><span class="n">y_prob</span><span class="p">.</span><span class="n">head</span><span class="p">()</span></code></pre></figure>

<p><img src="/assets/img/IntelAI/logError11.png" alt="Output" class="img-responsive" /></p>

<h1 id="error-metrics-1">Error Metrics</h1>

<p>For each model, calculate the following error metrics:</p>

<ul>
  <li>accuracy</li>
  <li>precision</li>
  <li>recall</li>
  <li>fscore</li>
  <li>confusion matrix</li>
</ul>

<p>Decide how to combine the multi-class metrics into a single value for each model.</p>

<figure class="highlight"><pre><code class="language-python" data-lang="python"><span class="kn">from</span> <span class="nn">sklearn.metrics</span> <span class="kn">import</span> <span class="n">precision_recall_fscore_support</span> <span class="k">as</span> <span class="n">score</span>
<span class="kn">from</span> <span class="nn">sklearn.metrics</span> <span class="kn">import</span> <span class="n">confusion_matrix</span><span class="p">,</span> <span class="n">accuracy_score</span><span class="p">,</span> <span class="n">roc_auc_score</span>
<span class="kn">from</span> <span class="nn">sklearn.preprocessing</span> <span class="kn">import</span> <span class="n">label_binarize</span>

<span class="n">metrics</span> <span class="o">=</span> <span class="nb">list</span><span class="p">()</span>
<span class="n">cm</span> <span class="o">=</span> <span class="nb">dict</span><span class="p">()</span>

<span class="k">for</span> <span class="n">lab</span> <span class="ow">in</span> <span class="n">coeff_labels</span><span class="p">:</span>

    <span class="c1"># Preciision, recall, f-score from the multi-class support function
</span>    <span class="n">precision</span><span class="p">,</span> <span class="n">recall</span><span class="p">,</span> <span class="n">fscore</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="n">score</span><span class="p">(</span><span class="n">Y_test_new</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">[</span><span class="n">lab</span><span class="p">],</span> <span class="n">average</span><span class="o">=</span><span class="s">'weighted'</span><span class="p">)</span>
    
    <span class="c1"># The usual way to calculate accuracy
</span>    <span class="n">accuracy</span> <span class="o">=</span> <span class="n">accuracy_score</span><span class="p">(</span><span class="n">Y_test_new</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">[</span><span class="n">lab</span><span class="p">])</span>
    
    <span class="c1"># ROC-AUC scores can be calculated by binarizing the data
</span>    <span class="n">auc</span> <span class="o">=</span> <span class="n">roc_auc_score</span><span class="p">(</span><span class="n">label_binarize</span><span class="p">(</span><span class="n">Y_test_new</span><span class="p">,</span> <span class="n">classes</span><span class="o">=</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span><span class="mi">1</span><span class="p">,</span><span class="mi">2</span><span class="p">,</span><span class="mi">3</span><span class="p">,</span><span class="mi">4</span><span class="p">,</span><span class="mi">5</span><span class="p">]),</span>
              <span class="n">label_binarize</span><span class="p">(</span><span class="n">y_pred</span><span class="p">[</span><span class="n">lab</span><span class="p">],</span> <span class="n">classes</span><span class="o">=</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span><span class="mi">1</span><span class="p">,</span><span class="mi">2</span><span class="p">,</span><span class="mi">3</span><span class="p">,</span><span class="mi">4</span><span class="p">,</span><span class="mi">5</span><span class="p">]),</span> 
              <span class="n">average</span><span class="o">=</span><span class="s">'weighted'</span><span class="p">)</span>
    
    <span class="c1"># Last, the confusion matrix
</span>    <span class="n">cm</span><span class="p">[</span><span class="n">lab</span><span class="p">]</span> <span class="o">=</span> <span class="n">confusion_matrix</span><span class="p">(</span><span class="n">Y_test_new</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">[</span><span class="n">lab</span><span class="p">])</span>
    
    <span class="n">metrics</span><span class="p">.</span><span class="n">append</span><span class="p">(</span><span class="n">pd</span><span class="p">.</span><span class="n">Series</span><span class="p">({</span><span class="s">'precision'</span><span class="p">:</span><span class="n">precision</span><span class="p">,</span> <span class="s">'recall'</span><span class="p">:</span><span class="n">recall</span><span class="p">,</span> 
                              <span class="s">'fscore'</span><span class="p">:</span><span class="n">fscore</span><span class="p">,</span> <span class="s">'accuracy'</span><span class="p">:</span><span class="n">accuracy</span><span class="p">,</span>
                              <span class="s">'auc'</span><span class="p">:</span><span class="n">auc</span><span class="p">},</span> 
                             <span class="n">name</span><span class="o">=</span><span class="n">lab</span><span class="p">))</span>

<span class="n">metrics</span> <span class="o">=</span> <span class="n">pd</span><span class="p">.</span><span class="n">concat</span><span class="p">(</span><span class="n">metrics</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>

<span class="n">metrics</span></code></pre></figure>

<p><img src="/assets/img/IntelAI/logError12.png" alt="Output" class="img-responsive" /></p>

<h1 id="confusion-matrix-1">Confusion Matrix</h1>
<p>Finally the confusion matrix for the new models.</p>

<figure class="highlight"><pre><code class="language-python" data-lang="python"><span class="n">fig</span><span class="p">,</span> <span class="n">axList</span> <span class="o">=</span> <span class="n">plt</span><span class="p">.</span><span class="n">subplots</span><span class="p">(</span><span class="n">nrows</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">ncols</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>
<span class="n">axList</span> <span class="o">=</span> <span class="n">axList</span><span class="p">.</span><span class="n">flatten</span><span class="p">()</span>
<span class="n">fig</span><span class="p">.</span><span class="n">set_size_inches</span><span class="p">(</span><span class="mi">12</span><span class="p">,</span> <span class="mi">10</span><span class="p">)</span>

<span class="n">axList</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">].</span><span class="n">axis</span><span class="p">(</span><span class="s">'off'</span><span class="p">)</span>

<span class="k">for</span> <span class="n">ax</span><span class="p">,</span><span class="n">lab</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="n">axList</span><span class="p">[:</span><span class="o">-</span><span class="mi">1</span><span class="p">],</span> <span class="n">coeff_labels</span><span class="p">):</span>
    <span class="n">sns</span><span class="p">.</span><span class="n">heatmap</span><span class="p">(</span><span class="n">cm</span><span class="p">[</span><span class="n">lab</span><span class="p">],</span> <span class="n">ax</span><span class="o">=</span><span class="n">ax</span><span class="p">,</span> <span class="n">annot</span><span class="o">=</span><span class="bp">True</span><span class="p">,</span> <span class="n">fmt</span><span class="o">=</span><span class="s">'d'</span><span class="p">);</span>
    <span class="n">ax</span><span class="p">.</span><span class="nb">set</span><span class="p">(</span><span class="n">title</span><span class="o">=</span><span class="n">lab</span><span class="p">);</span>
    
<span class="n">plt</span><span class="p">.</span><span class="n">tight_layout</span><span class="p">()</span></code></pre></figure>

<p><img src="/assets/img/IntelAI/logError13.png" alt="Output" class="img-responsive" /></p>

<p>Credits to <a href="https://software.intel.com/en-us/home">Intel AI Academy</a></p>


            </article>

            <section class="share">
    <h3>Share</h3>
    <a aria-label="Share on Twitter" href="https://twitter.com/intent/tweet?text=&quot;&quot;%20http://localhost:4000/Archive/2018-12-03-log-regress-classification-error/%20via%20&#64;jimmyable_&hashtags=python,logistic regression,machine learning,numpy,scikit,classification,ridge regression,error metrics,lasso regression,stratified shuffle split,"
    onclick="window.open(this.href, 'twitter-share', 'width=550,height=235');return false;" title="Share on Twitter">
        <svg class="icon icon-twitter"><use xlink:href="#icon-twitter"></use></svg>
    </a>
    <a aria-label="Share on Facebook"href="https://www.facebook.com/sharer/sharer.php?u=http://localhost:4000/Archive/2018-12-03-log-regress-classification-error/"
    onclick="window.open(this.href, 'facebook-share','width=580,height=296');return false;" title="Share on Facebook">
        <svg class="icon icon-facebook"><use xlink:href="#icon-facebook"></use></svg>
    </a>
    <a aria-label="Share on Google Plus" href="https://plus.google.com/share?url=http://localhost:4000/Archive/2018-12-03-log-regress-classification-error/"
    onclick="window.open(this.href, 'google-plus-share', 'width=490,height=530');return false;" title="Share on Google+">
        <svg class="icon icon-google-plus"><use xlink:href="#icon-google-plus"></use></svg>
    </a>
</section>
            <section class="author" itemprop="author">
    <div class="details" itemscope itemtype="http://schema.org/Person">
        <img itemprop="image" class="img-rounded" src="/assets/img/blog-author.jpg" alt="">
        <p class="def">Author</p>
        <h3 class="name">
            <a itemprop="name" href="http://jimmyjoseph.co.uk/about">Jimmy Joseph</a>
        </h3>
        <p class="desc">Author, Blogger, Computer Scientist, Designer, Engineer...</p>
        <a itemprop="email" class="email" href="mailto:jimmyjoseph@outlook.com">jimmyjoseph@outlook.com</a>
    </div>
</section>

            <!-- <section class="comments">
    <h3>Comments</h3>
    <div id="disqus_thread"></div>
</section>
<script type="text/javascript">
    var disqus_loaded = true;

    function load_disqus()
    {
        disqus_loaded = true;
        var disqus_shortname = '';
        var disqus_title = '';
        var disqus_url = '/Archive/2018-12-03-log-regress-classification-error/';
        var dsq = document.createElement('script'); dsq.type = 'text/javascript'; dsq.async = true;
        dsq.src = '//' + disqus_shortname + '.disqus.com/embed.js';
        (document.getElementsByTagName('head')[0] || document.getElementsByTagName('body')[0]).appendChild(dsq);
        var ldr = document.getElementById('disqus_loader');
    };
    window.onscroll = function(e) {
        if ((window.innerHeight + window.scrollY) >= (document.body.offsetHeight - 800)) {
            //hit bottom of page
            if (disqus_loaded==false)
                load_disqus()
        }
    };
</script>
 -->
            <footer>
    <p>Built with <a href="http://jekyllrb.com/" target="_blank"> Jekyll</a> by <span class="love"></span> <a href="https://willianjusten.com.br">Willian Justen</a></p>
</footer>
<script src="/assets/js/main.js"></script>

        </section>
    </body>
</html>
